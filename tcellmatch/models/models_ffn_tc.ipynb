{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! Imports aren't working...\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Aa Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerAaEmbedding(nn.Module):\n",
    "    \"\"\" A layer class that implements amino acid embedding.\n",
    "\n",
    "    Instances of this class can be used as layers in the context of tensorflow Models.\n",
    "    This layer implements 1x1 convolutions to map a given amino acid embedding (such as one-hot) into a learnable\n",
    "    new space of choosable dimensionality.\n",
    "\n",
    "    \"\"\"\n",
    "    sublayer_conv2d: torch.nn.Conv2d\n",
    "    fwd_pass: list\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            shape_embedding: int,\n",
    "            squeeze_2D_sequence: bool,\n",
    "            trainable: bool = True,\n",
    "            dropout: float = 0.1,\n",
    "            input_shape=None,\n",
    "            # dtype=tf.float32\n",
    "            dtype=torch.float32\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if shape_embedding < 0:\n",
    "            raise ValueError(\"aa_embedding_dim has to be >0\")\n",
    "        self.dropout = dropout\n",
    "        # self.input_shapes = input_shape\n",
    "        self.sublayer_conv2d = None\n",
    "        self.shape_embedding = shape_embedding if shape_embedding != 0 else input_shape[-1]\n",
    "        # !! Check in and out # channels\n",
    "        self.sublayer_conv2d = torch.nn.Conv1d(\n",
    "            # in_channels=input_shape[-1],\n",
    "            # out_channels=self.shape_embedding,\n",
    "            in_channels=26,\n",
    "            out_channels=20,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=True,\n",
    "            padding_mode='zeros'\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        if self.shape_embedding is not None:\n",
    "            x = self.sublayer_conv2d(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSa:\n",
    "\n",
    "    forward_pass: list\n",
    "    final_dense: list\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            labels_dim: int,\n",
    "            input_shapes: tuple,\n",
    "            attention_size: List[int],\n",
    "            attention_heads: List[int],\n",
    "            split: bool,\n",
    "            residual_connection=False,\n",
    "            aa_embedding_dim: Union[int, None] = 0,\n",
    "            depth_final_dense: int = 1,\n",
    "            out_activation: str = \"linear\",\n",
    "            dropout: float = 0.0\n",
    "    ):\n",
    "        \"\"\" Self-attention-based feed-forward network.\n",
    "\n",
    "        Build the feed forward network as a tf.keras.Model object.\n",
    "\n",
    "        :param dropout: drop out rate for lstm.\n",
    "        :param attention_size: hidden size for attention, could be divided by attention_heads.\n",
    "        :param attention_heads: number of heads in attention.\n",
    "        :param residual_connection: apply residual connection or not.\n",
    "        :param aa_embedding_dim: Dimension of the linear amino acid embedding, ie number of 1x1 convolutional filters.\n",
    "            This is set to the input dimension if aa_embedding_dim==0.\n",
    "        :param depth_final_dense: Number of final densely connected layers. They all have labels_dim number of units\n",
    "            and relu activation functions, apart from the last, which has either linear or sigmoid activation,\n",
    "            depending on out_probabilities.\n",
    "        :param out_activation: Identifier of output activation function, this depends on\n",
    "            assumption on labels and cost function:\n",
    "\n",
    "            - \"linear\" for binding strength data measured as counts\n",
    "            - \"sigmoid\" for binary binding events with multiple events per cell\n",
    "            - \"softmax\" for binary binding events with one event per cell\n",
    "        \"\"\"\n",
    "        self.args = {\n",
    "            \"labels_dim\": labels_dim,\n",
    "            \"input_shapes\": input_shapes,\n",
    "            \"attention_size\": attention_size,\n",
    "            \"attention_heads\": attention_heads,\n",
    "            \"residual_connection\": residual_connection,\n",
    "            \"aa_embedding_dim\": aa_embedding_dim,\n",
    "            \"depth_final_dense\": depth_final_dense,\n",
    "            \"out_activation\": out_activation,\n",
    "            \"dropout\": dropout,\n",
    "            \"split\": split\n",
    "        }\n",
    "        self.input_shapes = input_shapes\n",
    "        self.labels_dim = labels_dim\n",
    "        self.attention_size = attention_size\n",
    "        self.attention_heads = attention_heads\n",
    "        self.residual_connection = residual_connection\n",
    "        self.aa_embedding_dim = aa_embedding_dim\n",
    "        self.depth_final_dense = depth_final_dense\n",
    "        self.out_activation = out_activation\n",
    "        self.dropout = dropout\n",
    "        self.split = split\n",
    "        assert not split, \"not implemented\"\n",
    "        self.run_eagerly = False\n",
    "        self.x_len = input_shapes[4]\n",
    "\n",
    "        # input_tcr = tf.keras.layers.Input(\n",
    "        #     shape=(input_shapes[0], input_shapes[1], input_shapes[2]),\n",
    "        # )\n",
    "        input_tcr = torch.zeroes(input_shapes[0], input_shapes[1], input_shapes[2])\n",
    "        input_covar = torch.zeroes(input_shapes[3])\n",
    "        # input_covar = tf.keras.layers.Input(\n",
    "        #     shape=(input_shapes[3]),\n",
    "        #     name='input_covar'\n",
    "        # )\n",
    "\n",
    "        # Preprocessing:\n",
    "        x = input_tcr\n",
    "        # x = tf.squeeze(x, axis=[1])  # squeeze out chain\n",
    "        x = torch.squeeze(x, dim=1)  # squeeze out chain\n",
    "        x = 2 * (x - 0.5)\n",
    "        # Optional amino acid embedding:\n",
    "        if aa_embedding_dim is not None:\n",
    "            x = LayerAaEmbedding(\n",
    "                shape_embedding=self.aa_embedding_dim,\n",
    "                squeeze_2D_sequence=True\n",
    "            )(x)\n",
    "        # Self-attention layers.\n",
    "        for i, (w, n) in enumerate(zip(self.attention_size, self.attention_heads)):\n",
    "            x = LayerMultiheadSelfAttention(\n",
    "                width_embedding=w,\n",
    "                n_heads=n,\n",
    "                residual_connection=self.residual_connection,\n",
    "                attention_dropout=self.dropout,\n",
    "                name=\"sa_\" + str(i)\n",
    "            )(x)\n",
    "        x = tf.reshape(x, [-1, x.shape[1] * x.shape[2]])\n",
    "        # Optional concatenation of non-sequence covariates.\n",
    "        if input_covar.shape[1] > 0:\n",
    "            x = tf.concat([x, input_covar], axis=1)\n",
    "        # Final dense layers.from\n",
    "        self.final_dense = []\n",
    "        for i in range(self.depth_final_dense):\n",
    "            x = tf.keras.layers.Dense(\n",
    "                units=self.labels_dim,\n",
    "                activation=\"relu\" if i < self.depth_final_dense - 1 else self.out_activation.lower(),\n",
    "                use_bias=True,\n",
    "                kernel_initializer='glorot_uniform',\n",
    "                bias_initializer='zeros',\n",
    "                kernel_regularizer=None,\n",
    "                bias_regularizer=None,\n",
    "                activity_regularizer=None\n",
    "            )(x)\n",
    "        output = x\n",
    "\n",
    "        self.training_model = tf.keras.models.Model(\n",
    "            inputs=[input_tcr, input_covar],\n",
    "            outputs=output,\n",
    "            name='model_sa'\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerMultiheadSelfAttention(nn.Module):\n",
    "    \"\"\" Custom Linear layer but mimics a standard linear layer \"\"\"\n",
    "    def __init__(self, size_in, size_out):\n",
    "        super().__init__()\n",
    "        self.size_in, self.size_out = size_in, size_out\n",
    "        weights = torch.Tensor(size_out, size_in)\n",
    "        self.weights = nn.Parameter(weights)  # nn.Parameter is a Tensor that's a module parameter.\n",
    "        bias = torch.Tensor(size_out)\n",
    "        self.bias = nn.Parameter(bias)\n",
    "\n",
    "        # initialize weights and biases\n",
    "        nn.init.kaiming_uniform_(self.weights, a=math.sqrt(5)) # weight init\n",
    "        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weights)\n",
    "        bound = 1 / math.sqrt(fan_in)\n",
    "        nn.init.uniform_(self.bias, -bound, bound)  # bias init\n",
    "\n",
    "    def forward(self, x):\n",
    "        w_times_x= torch.mm(x, self.weights.t())\n",
    "        return torch.add(w_times_x, self.bias)  # w times x + b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcell-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
