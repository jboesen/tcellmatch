{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af24413",
   "metadata": {},
   "source": [
    "# Hyperparameter Search\n",
    "This notebook is an implementation of ``10x_dataset_training.ipynb`` with hyperparameter search. The hyperparameter search is done using Weights and Biases (wandb) and performed with the sweep method, a grid search with random sampling. The hyperparameters are:\n",
    "- ``learning_rate``: The learning rate of the optimizer.\n",
    "- ``num_specific_layers``: The number of model-specific layers (i.e., self-attention layers, convolutional layers, etc.).\n",
    "- ``aa_embedding_dim``: The dimension of the amino acid embedding.\n",
    "- ``depth_final_dense``: The number of linear layers in the network.\n",
    "- ``model_name``: The model to use. Either ``bilstm``, ``self_attention``, ``cnn``, or ``bigru``. See the ``README.md`` for more details about the implementations of these architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208b6333-9bc2-4057-b0af-180fdd582e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tcellmatch.api as tm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pytorch_model_summary import summary\n",
    "from torchmetrics import Accuracy\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d984895f-988f-4944-9c2d-ae0946148f72",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d1dd677-d229-49c8-b31d-e52417c55e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BIND_COUNTS = True\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "688c1d20-20fa-4276-aa43-b16adfdcaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    ffn = tm.models.EstimatorFfn()\n",
    "    indir = '../tutorial_data/'\n",
    "    data = np.load(f\"{indir}ffn_data_continuous_15k.npz\")\n",
    "    ffn.x_train = data[\"x_train\"]\n",
    "    ffn.covariates_train = data[\"covariates_train\"]\n",
    "    ffn.y_train = data[\"y_train\"]\n",
    "    ffn.x_test = data[\"x_test\"]\n",
    "    ffn.covariates_test = data[\"covariates_test\"]\n",
    "    ffn.y_test = data[\"y_test\"]\n",
    "    ffn.clone_train = data[\"clone_train\"]\n",
    "    ffn.load_idx(f'{indir}SAVED_IDX')\n",
    "    \n",
    "    sums_across_last_dim = np.sum(ffn.x_train, axis=-1)\n",
    "\n",
    "    # Find rows which are not \"zero-hot\"\n",
    "    non_zero_hot_rows = np.any(sums_across_last_dim > 0, axis=-1)\n",
    "    non_zero_hot_rows = np.squeeze(non_zero_hot_rows)\n",
    "    \n",
    "    ffn.x_train = ffn.x_train[non_zero_hot_rows]\n",
    "    ffn.y_train = ffn.y_train[non_zero_hot_rows]\n",
    "    return ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f10cd5c-ec2b-4ce7-8a84-de7704a9f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize wandb with a sample project name\n",
    "\n",
    "config = wandb.config\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "aa_embedding_dim = 1\n",
    "depth_final_dense = 1\n",
    "ffn = load_model()\n",
    "\n",
    "\n",
    "attention_size = [128] * 1\n",
    "attention_heads = [16] * 1\n",
    "\n",
    "ffn.build_self_attention(\n",
    "    residual_connection=True,\n",
    "    aa_embedding_dim=aa_embedding_dim,\n",
    "    attention_size=attention_size,\n",
    "    use_covariates=False,\n",
    "    attention_heads=attention_heads,\n",
    "    depth_final_dense=depth_final_dense,\n",
    "    optimizer='adam',\n",
    "    lr=lr,\n",
    "    loss='pois' if USE_BIND_COUNTS else 'wbce',\n",
    "    label_smoothing=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0e86d",
   "metadata": {},
   "source": [
    "# Add WandB Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f669bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "   'method': 'grid',  # can be random, grid, bayes\n",
    "   'parameters': {\n",
    "       'lr': {  # learning rate\n",
    "           'values': [0.001, 0.005, 0.01, 0.1]\n",
    "       },\n",
    "       'aa_embedding_dim': {\n",
    "           'values': [0, 10, 26]\n",
    "       },\n",
    "       'depth_final_dense': {\n",
    "           'values': [1, 2, 3, 5, 9]\n",
    "       },\n",
    "       'model_name': {\n",
    "           'values': ['self-attention', 'bilstm', 'bigru', 'cnn']\n",
    "       },\n",
    "       # i.e., bilstm depth, SA depth, conv depth\n",
    "       'specific_layer_depth': {\n",
    "            'values': [1, 2, 3, 4, 5]\n",
    "       }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbf54108-744e-4e54-83e6-68cfa9bd3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Initialize wandb with a sample project name\n",
    "    wandb.init(project=\"TCR fitting\")\n",
    "\n",
    "    config = wandb.config\n",
    "   \n",
    "    # replace your hard-coded hyperparameters with config values\n",
    "    model_name = config.model_name\n",
    "    lr = config.lr\n",
    "    aa_embedding_dim = config.aa_embedding_dim\n",
    "    depth_final_dense = config.depth_final_dense\n",
    "    ffn = load_model()\n",
    "\n",
    "    if model_name.lower() == 'self-attention':\n",
    "        attention_size = [128] * config.specific_layer_depth\n",
    "        attention_heads = [16] * config.specific_layer_depth\n",
    "\n",
    "        ffn.build_self_attention(\n",
    "            residual_connection=True,\n",
    "            aa_embedding_dim=aa_embedding_dim,\n",
    "            attention_size=attention_size,\n",
    "            use_covariates=False,\n",
    "            attention_heads=attention_heads,\n",
    "            depth_final_dense=depth_final_dense,\n",
    "            optimizer='adam',\n",
    "            lr=lr,\n",
    "            loss='pois' if USE_BIND_COUNTS else 'wbce',\n",
    "            label_smoothing=0\n",
    "        )\n",
    "    elif model_name.lower() == 'bilstm':\n",
    "        topology = [32] * config.specific_layer_depth\n",
    "        ffn.build_bilstm(\n",
    "            topology=topology,\n",
    "            residual_connection=True,\n",
    "            aa_embedding_dim=aa_embedding_dim,\n",
    "            optimizer='adam',\n",
    "            lr=lr,\n",
    "            loss='pois' if USE_BIND_COUNTS else 'wcbe',\n",
    "            label_smoothing=0,\n",
    "            depth_final_dense=depth_final_dense,\n",
    "            use_covariates=False,\n",
    "            one_hot_y=not USE_BIND_COUNTS\n",
    "        )\n",
    "    elif model_name.lower() == 'bigru':\n",
    "        topology= [10] * config.specific_layer_depth\n",
    "        ffn.build_bigru(\n",
    "            aa_embedding_dim=aa_embedding_dim,\n",
    "            residual_connection=True,\n",
    "            lr=lr,\n",
    "            loss='pois' if USE_BIND_COUNTS else 'wbce',\n",
    "        )\n",
    "    elif model_name.lower() == 'cnn':\n",
    "        n_conv_layers = config.specific_layer_depth\n",
    "        # filter_widths = [3, 5, 3] \n",
    "        # filters = [16, 32, 64]\n",
    "        pool_sizes = [2] * n_conv_layers\n",
    "        pool_strides = [2] * n_conv_layers\n",
    "        ffn.build_conv(\n",
    "            n_conv_layers=n_conv_layers,\n",
    "            depth_final_dense=depth_final_dense,\n",
    "            # filter_widths=filter_widths,\n",
    "            # filters=filters,\n",
    "            pool_sizes=pool_sizes,\n",
    "            pool_strides=pool_strides,\n",
    "            loss='pois' if USE_BIND_COUNTS else 'wbce',\n",
    "        )\n",
    "\n",
    "    # Training model\n",
    "    EPOCHS = 5\n",
    "    batch_size = 16\n",
    "    ffn.model = ffn.model.to(device=device)\n",
    "    train_curve, val_curve, antigen_loss, antigen_loss_val = ffn.train(\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=batch_size,\n",
    "        log_dir='training_runs',\n",
    "        allow_early_stopping=False,\n",
    "        print_loss=False,\n",
    "        lr_schedule_factor=0.99999,\n",
    "        use_wandb=True\n",
    "    )\n",
    "   \n",
    "    # Log metrics with wandb\n",
    "    wandb.log({'Train Loss': train_curve[-1], 'Validation Loss': val_curve[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4b348bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: tzxirs4o\n",
      "Sweep URL: https://wandb.ai/jmboesen/uncategorized/sweeps/tzxirs4o\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20d95c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4ukda19b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taa_embedding_dim: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdepth_final_dense: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: self-attention\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspecific_layer_depth: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "VBox(children=(Label(value='0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)))\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/johnboesen/tcellmatch-container/tutorials/wandb/run-20230721_160820-4ukda19b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jmboesen/uncategorized/runs/4ukda19b' target=\"_blank\">scarlet-sweep-1</a></strong> to <a href='https://wandb.ai/jmboesen/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jmboesen/uncategorized/sweeps/tzxirs4o' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized/sweeps/tzxirs4o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jmboesen/uncategorized' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jmboesen/uncategorized/sweeps/tzxirs4o' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized/sweeps/tzxirs4o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jmboesen/uncategorized/runs/4ukda19b' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized/runs/4ukda19b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started training...\n",
      "Number of observations in evaluation data: 1459\n",
      "Number of observations in training data: 13541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f4eeb252660> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/backcall/backcall.py:104\u001b[0m, in \u001b[0;36mcallback_prototype.<locals>.adapt.<locals>.adapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 kwargs\u001b[38;5;241m.\u001b[39mpop(name)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m callback(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:419\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface\u001b[38;5;241m.\u001b[39mpublish_pause()\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:664\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    663\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_pause(pause)\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:340\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish(rec)\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock_client\u001b[38;5;241m.\u001b[39msend_record_publish(record)\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend_server_request(server_req)\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_message(msg)\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sendall_with_error_handle(header \u001b[38;5;241m+\u001b[39m data)\n",
      "File \u001b[0;32m~/.conda/envs/jboesen/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msend(data)\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04c93a-20d3-4b5b-af2c-cf1ca9ef1264",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jboesen tcellmatch",
   "language": "python",
   "name": "jboesen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
