{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af24413",
   "metadata": {},
   "source": [
    "# Hyperparameter Search\n",
    "This notebook is an implementation of ``10x_dataset_training.ipynb`` with hyperparameter search. The hyperparameter search is done using Weights and Biases (wandb) and performed with the sweep method, a grid search with random sampling. The hyperparameters are:\n",
    "- ``learning_rate``: The learning rate of the optimizer.\n",
    "- ``num_specific_layers``: The number of model-specific layers (i.e., self-attention layers, convolutional layers, etc.).\n",
    "- ``aa_embedding_dim``: The dimension of the amino acid embedding.\n",
    "- ``depth_final_dense``: The number of linear layers in the network.\n",
    "- ``model_name``: The model to use. Either ``bilstm``, ``self_attention``, ``cnn``, or ``bigru``. See the ``README.md`` for more details about the implementations of these architectures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208b6333-9bc2-4057-b0af-180fdd582e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tcellmatch.api as tm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pytorch_model_summary import summary\n",
    "from torchmetrics import Accuracy\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f2078a-fc09-4550-b3c7-14602257e274",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284466c4-5f02-4011-b17b-24b6e800bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    print('loading model...')\n",
    "    ffn = tm.models.EstimatorFfn()\n",
    "    indir = '../tutorial_data/'\n",
    "    data = np.load(f\"{indir}ffn_data_continuous_15k.npz\")\n",
    "    ffn.x_train = data[\"x_train\"]\n",
    "    ffn.covariates_train = data[\"covariates_train\"]\n",
    "    ffn.y_train = data[\"y_train\"]\n",
    "    ffn.x_test = data[\"x_test\"]\n",
    "    ffn.covariates_test = data[\"covariates_test\"]\n",
    "    ffn.y_test = data[\"y_test\"]\n",
    "    ffn.clone_train = data[\"clone_train\"]\n",
    "    ffn.load_idx(f'{indir}SAVED_IDX')\n",
    "    sums_across_last_dim = np.sum(ffn.x_train, axis=-1)\n",
    "\n",
    "    # Find rows which are not \"zero-hot\"\n",
    "    non_zero_hot_rows = np.any(sums_across_last_dim > 0, axis=-1)\n",
    "\n",
    "    ffn.x_train = ffn.x_train[non_zero_hot_rows]\n",
    "    ffn.x_train = ffn.x_train[:, np.newaxis, :]\n",
    "    return ffn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aabdc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 1, 40, 26) (15000, 50) (15000, 2)\n",
      "[128] [16]\n",
      "built\n",
      "ak to train\n",
      "started training...\n",
      "pre partition\n",
      "Number of observations in evaluation data: 1526\n",
      "Number of observations in training data: 13474\n",
      "post partition partition\n",
      "loaded up data\n",
      "At beginning of epoch...\n",
      "2.580904483795166\n",
      "2.3816614151000977\n",
      "3.5810325145721436\n",
      "3.226235866546631\n",
      "2.259986162185669\n",
      "1.0143965482711792\n",
      "1.2908402681350708\n",
      "1.4610847234725952\n",
      "0.8280069828033447\n",
      "1.0991848707199097\n",
      "1.5233083963394165\n",
      "3.7885024547576904\n",
      "1.2976499795913696\n",
      "0.7468215823173523\n",
      "1.4784337282180786\n",
      "1.5324702262878418\n",
      "1.0549285411834717\n",
      "2.525811195373535\n",
      "0.9838641285896301\n",
      "2.117570400238037\n",
      "1.357994556427002\n",
      "4.205320358276367\n",
      "1.6021696329116821\n",
      "1.1233086585998535\n",
      "0.9501087665557861\n",
      "1.0942893028259277\n",
      "1.0694996118545532\n",
      "2.4533028602600098\n",
      "0.9575803279876709\n",
      "1.3155338764190674\n",
      "1.5218037366867065\n",
      "0.6309264302253723\n",
      "0.8096922039985657\n",
      "3.459019660949707\n",
      "2.248868703842163\n",
      "2.23818302154541\n",
      "1.6943048238754272\n",
      "2.4967267513275146\n",
      "1.1491695642471313\n",
      "0.9427857398986816\n",
      "1.3965595960617065\n",
      "1.023480772972107\n",
      "0.5821982622146606\n",
      "1.2329013347625732\n",
      "1.5261340141296387\n",
      "0.960650622844696\n",
      "0.9728608131408691\n",
      "0.7190545797348022\n",
      "1.7733850479125977\n",
      "0.6832747459411621\n",
      "0.7882015705108643\n",
      "2.473416328430176\n",
      "1.025903344154358\n",
      "0.5083590149879456\n",
      "0.7022255063056946\n",
      "0.6884286403656006\n",
      "1.406394600868225\n",
      "0.7815199494361877\n",
      "1.4847006797790527\n",
      "1.6301623582839966\n",
      "1.4958328008651733\n",
      "0.8196260333061218\n",
      "0.8927238583564758\n",
      "0.7608739733695984\n",
      "1.2487438917160034\n",
      "0.6577058434486389\n",
      "1.641389012336731\n",
      "1.000974416732788\n",
      "3.2949960231781006\n",
      "2.0729241371154785\n",
      "0.6744182705879211\n",
      "3.5406460762023926\n",
      "4.258882999420166\n",
      "0.687816858291626\n",
      "0.8495886325836182\n",
      "3.537707567214966\n",
      "1.3752533197402954\n",
      "1.184751033782959\n",
      "1.2530286312103271\n",
      "1.0541589260101318\n",
      "0.7112091779708862\n",
      "1.0075387954711914\n",
      "0.659128725528717\n",
      "1.4174200296401978\n",
      "1.7516276836395264\n",
      "0.6157259345054626\n",
      "0.46506989002227783\n",
      "1.5142607688903809\n",
      "0.4923820495605469\n",
      "2.051828145980835\n",
      "0.6301072835922241\n",
      "0.5087435245513916\n",
      "0.9794185161590576\n",
      "1.4754239320755005\n",
      "1.200784683227539\n",
      "0.7115137577056885\n",
      "0.5583348870277405\n",
      "0.49055349826812744\n",
      "1.4366917610168457\n",
      "0.639279305934906\n",
      "1.0265698432922363\n",
      "1.2967267036437988\n",
      "1.009558081626892\n",
      "0.6511968374252319\n",
      "0.9777295589447021\n",
      "1.7343826293945312\n",
      "0.481953501701355\n",
      "1.169241189956665\n",
      "1.7700697183609009\n",
      "0.863667368888855\n",
      "0.563838005065918\n",
      "2.0757193565368652\n",
      "0.7353526949882507\n",
      "1.5294561386108398\n",
      "1.606590986251831\n",
      "1.1757018566131592\n",
      "0.9035671949386597\n",
      "1.1281813383102417\n",
      "0.6300977468490601\n",
      "2.8672499656677246\n",
      "0.7864570021629333\n",
      "1.4704891443252563\n",
      "0.5731034874916077\n",
      "1.0323256254196167\n",
      "0.6443994641304016\n",
      "0.4230252802371979\n",
      "3.392082929611206\n",
      "2.197885036468506\n",
      "0.8640013337135315\n",
      "1.3890527486801147\n",
      "1.6002427339553833\n",
      "1.7450170516967773\n",
      "1.082993507385254\n",
      "0.8608251214027405\n",
      "0.8921642899513245\n",
      "1.217106580734253\n",
      "1.788106083869934\n",
      "0.6746680736541748\n",
      "1.9448022842407227\n",
      "3.2973427772521973\n",
      "0.6107850074768066\n",
      "0.5997085571289062\n",
      "1.0120713710784912\n",
      "1.0865912437438965\n",
      "0.6092250943183899\n",
      "0.5723398923873901\n",
      "0.7392337322235107\n",
      "0.659467875957489\n",
      "3.454331874847412\n",
      "0.5125686526298523\n",
      "1.2713278532028198\n",
      "0.4787600040435791\n",
      "1.5979981422424316\n",
      "0.4297856092453003\n",
      "0.6500004529953003\n",
      "2.3401939868927\n",
      "1.3412402868270874\n",
      "0.8872912526130676\n",
      "0.5813314914703369\n",
      "1.1819381713867188\n",
      "2.393106698989868\n",
      "0.6525924801826477\n",
      "1.6319433450698853\n",
      "5.430405139923096\n",
      "1.0904651880264282\n",
      "0.5456392765045166\n",
      "0.6809245944023132\n",
      "1.0146987438201904\n",
      "0.7152045369148254\n",
      "1.293441891670227\n",
      "0.7777886390686035\n",
      "1.691575050354004\n",
      "1.4910670518875122\n",
      "3.588235855102539\n",
      "1.5920504331588745\n",
      "0.6990509629249573\n",
      "0.5169163942337036\n",
      "0.9186878800392151\n",
      "0.7670108675956726\n",
      "1.337445855140686\n",
      "2.6482105255126953\n",
      "0.5248336791992188\n",
      "1.5478157997131348\n",
      "0.7434160113334656\n",
      "3.2066500186920166\n",
      "0.8911331295967102\n",
      "0.816733717918396\n",
      "1.4211468696594238\n",
      "0.5942089557647705\n",
      "1.0317959785461426\n",
      "0.9307342767715454\n",
      "1.8277298212051392\n",
      "0.604810357093811\n",
      "1.7009038925170898\n",
      "1.4511793851852417\n",
      "0.7248817682266235\n",
      "4.486059188842773\n",
      "1.2892512083053589\n",
      "0.563729465007782\n",
      "0.9656232595443726\n",
      "1.2985224723815918\n",
      "0.8813019394874573\n",
      "1.6220937967300415\n",
      "0.6033161282539368\n",
      "0.690895140171051\n",
      "1.5752521753311157\n",
      "0.7706132531166077\n",
      "3.6399154663085938\n",
      "0.6146891117095947\n",
      "0.679985523223877\n",
      "1.0228241682052612\n",
      "0.6993057727813721\n",
      "0.61855149269104\n",
      "1.8040851354599\n",
      "1.6202906370162964\n",
      "0.5920482873916626\n",
      "0.7157154679298401\n",
      "0.5943188667297363\n",
      "0.8201948404312134\n",
      "0.7153031826019287\n",
      "0.9236490726470947\n",
      "2.003497838973999\n",
      "0.3968096077442169\n",
      "2.0344343185424805\n",
      "0.4890202283859253\n",
      "0.5729884505271912\n",
      "3.600419044494629\n",
      "2.03924560546875\n",
      "0.7064116597175598\n",
      "0.5409717559814453\n",
      "3.0919485092163086\n",
      "0.7784819602966309\n",
      "1.1227573156356812\n",
      "0.800549328327179\n",
      "1.3300861120224\n",
      "1.269443154335022\n",
      "0.7570992112159729\n",
      "2.462782382965088\n",
      "0.7177909016609192\n",
      "1.565675973892212\n",
      "1.061461091041565\n",
      "1.3996013402938843\n",
      "2.6727099418640137\n",
      "0.38902077078819275\n",
      "3.156740188598633\n",
      "0.9562816023826599\n",
      "0.7298294305801392\n",
      "2.0339386463165283\n",
      "0.8053635954856873\n",
      "1.3910199403762817\n",
      "0.7250619530677795\n",
      "2.2347588539123535\n",
      "1.5005600452423096\n",
      "1.3363629579544067\n",
      "0.5072993040084839\n",
      "1.3264591693878174\n",
      "0.807644248008728\n",
      "1.4014478921890259\n",
      "1.3789680004119873\n",
      "1.7148997783660889\n",
      "1.5443016290664673\n",
      "2.1939940452575684\n",
      "0.9479191303253174\n",
      "0.9659030437469482\n",
      "2.4781322479248047\n",
      "0.7913482785224915\n",
      "0.8332170248031616\n",
      "1.5280178785324097\n",
      "1.7863624095916748\n",
      "1.1927093267440796\n",
      "0.9365490674972534\n",
      "1.9108798503875732\n",
      "0.4645230174064636\n",
      "0.9756336212158203\n",
      "1.9668792486190796\n",
      "0.5556929707527161\n",
      "0.6838545799255371\n",
      "0.719780445098877\n",
      "1.449955701828003\n",
      "0.6302263140678406\n",
      "1.1926311254501343\n",
      "1.0969760417938232\n",
      "1.30973482131958\n",
      "2.2882325649261475\n",
      "0.7861328125\n",
      "0.7613685727119446\n",
      "0.8733835816383362\n",
      "0.6065152883529663\n",
      "0.6966579556465149\n",
      "0.9452637434005737\n",
      "4.634199619293213\n",
      "1.158801555633545\n",
      "2.072566270828247\n",
      "1.5756170749664307\n",
      "1.0114036798477173\n",
      "3.999851703643799\n",
      "0.9523340463638306\n",
      "0.9175617694854736\n",
      "1.2439048290252686\n",
      "1.669458031654358\n",
      "1.0870176553726196\n",
      "0.9375966787338257\n",
      "1.2678948640823364\n",
      "1.3559504747390747\n",
      "0.5495365262031555\n",
      "1.0308469533920288\n",
      "0.6591423153877258\n",
      "1.1240887641906738\n",
      "0.8275898694992065\n",
      "1.2489573955535889\n",
      "0.5547863245010376\n",
      "0.9853284955024719\n",
      "0.49028900265693665\n",
      "0.554596483707428\n",
      "0.8969143033027649\n",
      "1.1110622882843018\n",
      "0.6352905631065369\n",
      "1.9723427295684814\n",
      "0.6402788758277893\n",
      "0.9227028489112854\n",
      "0.8107420206069946\n",
      "0.5624569058418274\n",
      "0.5500089526176453\n",
      "0.7155644297599792\n",
      "2.068995475769043\n",
      "1.3399994373321533\n",
      "0.8650484681129456\n",
      "2.246269941329956\n",
      "0.9906259179115295\n",
      "0.7028552889823914\n",
      "0.8811267018318176\n",
      "1.72691011428833\n",
      "0.4692094027996063\n",
      "0.45044562220573425\n",
      "0.7943243384361267\n",
      "2.4379868507385254\n",
      "1.6683140993118286\n",
      "0.6429263949394226\n",
      "0.7494959831237793\n",
      "2.3691015243530273\n",
      "1.171108365058899\n",
      "2.1107892990112305\n",
      "1.5366672277450562\n",
      "0.7619882225990295\n",
      "0.6015409231185913\n",
      "3.214406728744507\n",
      "0.7992364764213562\n",
      "0.6592891812324524\n",
      "1.1726285219192505\n",
      "1.1829290390014648\n",
      "3.2010927200317383\n",
      "0.5293079018592834\n",
      "1.073531150817871\n",
      "0.8178369402885437\n",
      "2.473026990890503\n",
      "1.4708210229873657\n",
      "0.5845762491226196\n",
      "0.6082271337509155\n",
      "0.7540386319160461\n",
      "0.9338639974594116\n",
      "0.9381049871444702\n",
      "1.8875614404678345\n",
      "1.7597689628601074\n",
      "0.870198130607605\n",
      "0.5151957869529724\n",
      "0.5083177089691162\n",
      "4.644908905029297\n",
      "0.9412714242935181\n",
      "0.7821571230888367\n",
      "1.4499493837356567\n",
      "0.4360024631023407\n",
      "0.9722319841384888\n",
      "1.6941490173339844\n",
      "2.091303825378418\n",
      "1.956162691116333\n",
      "0.6047292947769165\n",
      "1.4576367139816284\n",
      "1.089268445968628\n",
      "1.0774366855621338\n",
      "1.2636744976043701\n",
      "0.9557608962059021\n",
      "0.6322512626647949\n",
      "0.8897470831871033\n",
      "0.9219661951065063\n",
      "0.43837970495224\n",
      "1.0366827249526978\n",
      "0.4951401948928833\n",
      "0.8871999382972717\n",
      "0.8441227674484253\n",
      "1.3755793571472168\n",
      "0.7362755537033081\n",
      "2.2925450801849365\n",
      "1.7912805080413818\n",
      "1.89085054397583\n",
      "1.8555207252502441\n",
      "0.7994882464408875\n",
      "0.7343711853027344\n",
      "0.5825784802436829\n",
      "1.0283362865447998\n",
      "2.8266613483428955\n",
      "1.107046127319336\n",
      "0.6661771535873413\n",
      "0.8141307830810547\n",
      "0.4827173948287964\n",
      "0.5525920987129211\n",
      "0.47028782963752747\n",
      "1.861094355583191\n",
      "1.066166877746582\n",
      "1.2233494520187378\n",
      "0.5120185017585754\n",
      "0.9256842732429504\n",
      "2.2255778312683105\n",
      "0.9746161699295044\n",
      "0.7403072118759155\n",
      "1.3058151006698608\n",
      "1.8048678636550903\n",
      "0.5555983185768127\n",
      "1.538872241973877\n",
      "1.1373566389083862\n",
      "0.5208256244659424\n",
      "1.2592607736587524\n",
      "0.7725222706794739\n",
      "0.6459313035011292\n",
      "0.645835816860199\n",
      "0.5385122895240784\n",
      "0.504845917224884\n",
      "1.9899775981903076\n",
      "0.947116494178772\n",
      "3.1089072227478027\n",
      "2.4545180797576904\n",
      "1.775649070739746\n",
      "0.5473511219024658\n",
      "3.381901502609253\n",
      "1.1677716970443726\n",
      "1.2531684637069702\n",
      "2.42899227142334\n",
      "0.4471360146999359\n",
      "0.5642482042312622\n",
      "0.6240363121032715\n",
      "0.4482664465904236\n",
      "0.5171889066696167\n",
      "0.9907354712486267\n",
      "0.5089528560638428\n",
      "1.2736222743988037\n",
      "0.6417278051376343\n",
      "1.5325514078140259\n",
      "1.0214450359344482\n",
      "0.8419521450996399\n",
      "1.8577574491500854\n",
      "0.6565052270889282\n",
      "1.1163601875305176\n",
      "0.688712477684021\n",
      "0.7932823896408081\n",
      "0.7183578014373779\n",
      "0.520950973033905\n",
      "0.5590333342552185\n",
      "1.8681482076644897\n",
      "1.0827981233596802\n",
      "0.7729319930076599\n",
      "0.7036587595939636\n",
      "0.48882561922073364\n",
      "0.8378630876541138\n",
      "0.4380140006542206\n",
      "0.9238060116767883\n",
      "1.0361754894256592\n",
      "0.6866136193275452\n",
      "0.7404485940933228\n",
      "1.170717716217041\n",
      "1.1446106433868408\n",
      "0.9427487254142761\n",
      "1.3367670774459839\n",
      "2.264348030090332\n",
      "1.1867505311965942\n",
      "0.6633537411689758\n",
      "0.5899612903594971\n",
      "0.4929784834384918\n",
      "0.5363221764564514\n",
      "1.3757526874542236\n",
      "0.4311715364456177\n",
      "0.5283668637275696\n",
      "1.0040678977966309\n",
      "0.49971285462379456\n",
      "0.5916171073913574\n",
      "0.7571454048156738\n",
      "0.42713287472724915\n",
      "0.6636779308319092\n",
      "0.4074423909187317\n",
      "0.32218506932258606\n",
      "0.3963163495063782\n",
      "0.4321978688240051\n",
      "0.3754696249961853\n",
      "0.4237540066242218\n",
      "1.5096635818481445\n",
      "1.1549474000930786\n",
      "1.236122488975525\n",
      "1.0059678554534912\n",
      "0.6768191456794739\n",
      "0.761515736579895\n",
      "0.4790514409542084\n",
      "0.7854698896408081\n",
      "2.290452003479004\n",
      "0.6804836392402649\n",
      "0.5955971479415894\n",
      "1.4748404026031494\n",
      "1.0550650358200073\n",
      "0.9141139388084412\n",
      "1.201642632484436\n",
      "0.8625035881996155\n",
      "0.6719546318054199\n",
      "0.5690529346466064\n",
      "0.7812290191650391\n",
      "0.6119493842124939\n",
      "1.432511329650879\n",
      "0.8743895888328552\n",
      "0.5365259647369385\n",
      "0.721182644367218\n",
      "0.4305803179740906\n",
      "0.5365958213806152\n",
      "0.41433241963386536\n",
      "0.8447788953781128\n",
      "0.4909299612045288\n",
      "0.45795151591300964\n",
      "6.0072221755981445\n",
      "1.7392263412475586\n",
      "0.7770538926124573\n",
      "1.2172341346740723\n",
      "1.9787721633911133\n",
      "0.7043143510818481\n",
      "0.6145894527435303\n",
      "1.6442033052444458\n",
      "0.9762394428253174\n",
      "0.7154208421707153\n",
      "0.5648986101150513\n",
      "1.140580415725708\n",
      "1.1697306632995605\n",
      "0.6252958178520203\n",
      "0.5833840370178223\n",
      "0.8695957660675049\n",
      "0.5108011364936829\n",
      "0.49198973178863525\n",
      "2.22456431388855\n",
      "1.61415433883667\n",
      "1.741614580154419\n",
      "0.4575256407260895\n",
      "0.5344415903091431\n",
      "0.9342924356460571\n",
      "1.0076758861541748\n",
      "0.9619055390357971\n",
      "0.6136088371276855\n",
      "0.7873474955558777\n",
      "1.92262601852417\n",
      "0.4734763205051422\n",
      "2.674041986465454\n",
      "0.6289053559303284\n",
      "0.6640899181365967\n",
      "0.4173690378665924\n",
      "1.7487552165985107\n",
      "1.000252604484558\n",
      "1.5878223180770874\n",
      "0.5997061133384705\n",
      "0.7623315453529358\n",
      "2.342712879180908\n",
      "0.8799865245819092\n",
      "0.5196346640586853\n",
      "1.0509601831436157\n",
      "0.8719114065170288\n",
      "0.6668193936347961\n",
      "1.4030460119247437\n",
      "0.4826319217681885\n",
      "0.5676686763763428\n",
      "0.45859596133232117\n",
      "1.3718875646591187\n",
      "1.8750897645950317\n",
      "1.0201482772827148\n",
      "0.7303651571273804\n",
      "0.5510714054107666\n",
      "2.0392870903015137\n",
      "0.5317392945289612\n",
      "0.5952929854393005\n",
      "0.8222882747650146\n",
      "1.4238793849945068\n",
      "3.976384162902832\n",
      "0.6352490782737732\n",
      "0.8426700830459595\n",
      "1.3003430366516113\n",
      "2.4682936668395996\n",
      "1.3322333097457886\n",
      "0.9654554128646851\n",
      "0.4443880319595337\n",
      "0.5765977501869202\n",
      "0.5618449449539185\n",
      "0.5391905307769775\n",
      "0.5286243557929993\n",
      "0.49356499314308167\n",
      "1.5316004753112793\n",
      "0.8168424963951111\n",
      "0.8024194240570068\n",
      "1.7825361490249634\n",
      "0.6254300475120544\n",
      "1.0160140991210938\n",
      "0.6196205615997314\n",
      "0.5349910259246826\n",
      "0.787810742855072\n",
      "0.4845334589481354\n",
      "0.4343818426132202\n",
      "0.7896636128425598\n",
      "0.5332027673721313\n",
      "0.5421862006187439\n",
      "0.8203877806663513\n",
      "1.8661918640136719\n",
      "0.5395913124084473\n",
      "0.462502658367157\n",
      "2.5391480922698975\n",
      "0.8992058634757996\n",
      "0.5623798966407776\n",
      "0.6299142837524414\n",
      "0.39535629749298096\n",
      "0.6918541789054871\n",
      "0.6105731129646301\n",
      "2.1934423446655273\n",
      "0.542736828327179\n",
      "1.2303991317749023\n",
      "0.5087990760803223\n",
      "1.2985289096832275\n",
      "0.6150224208831787\n",
      "1.193442702293396\n",
      "0.8371724486351013\n",
      "0.9636622667312622\n",
      "0.7357845306396484\n",
      "0.8235911726951599\n",
      "0.7162061929702759\n",
      "1.6148196458816528\n",
      "1.6124465465545654\n",
      "0.5379383563995361\n",
      "0.4921911954879761\n",
      "0.9573379755020142\n",
      "0.562040388584137\n",
      "0.9974701404571533\n",
      "0.818309485912323\n",
      "1.7161648273468018\n",
      "1.4465123414993286\n",
      "1.3512672185897827\n",
      "0.5005656480789185\n",
      "1.0521185398101807\n",
      "0.5818849205970764\n",
      "1.0090445280075073\n",
      "2.817709445953369\n",
      "1.3359100818634033\n",
      "0.556692898273468\n",
      "2.6057143211364746\n",
      "2.4061954021453857\n",
      "0.838000476360321\n",
      "0.7703829407691956\n",
      "0.9056789875030518\n",
      "4.691122531890869\n",
      "0.5485865473747253\n",
      "0.7631886005401611\n",
      "0.7680777907371521\n",
      "0.6067328453063965\n",
      "0.6454476714134216\n",
      "1.060766339302063\n",
      "1.8630383014678955\n",
      "0.8932295441627502\n",
      "1.0356520414352417\n",
      "0.6135643124580383\n",
      "1.0282279253005981\n",
      "1.5376458168029785\n",
      "1.0790239572525024\n",
      "1.4826351404190063\n",
      "0.6719306707382202\n",
      "1.0669844150543213\n",
      "2.5376405715942383\n",
      "0.9239922165870667\n",
      "1.03145170211792\n",
      "1.5997483730316162\n",
      "1.284040927886963\n",
      "0.6010532975196838\n",
      "0.42019161581993103\n",
      "0.48073533177375793\n",
      "0.8029122948646545\n",
      "0.5177924633026123\n",
      "1.4915263652801514\n",
      "1.5777338743209839\n",
      "0.5726274847984314\n",
      "0.5112455487251282\n",
      "0.8276530504226685\n",
      "1.939913272857666\n",
      "0.9419882893562317\n",
      "1.0524901151657104\n",
      "0.4570893347263336\n",
      "0.42908695340156555\n",
      "1.2738871574401855\n",
      "0.5836492776870728\n",
      "1.8475074768066406\n",
      "0.4332830011844635\n",
      "0.7858500480651855\n",
      "1.1925925016403198\n",
      "0.8247209787368774\n",
      "0.7818030714988708\n",
      "0.5047111511230469\n",
      "0.7612225413322449\n",
      "0.6292890310287476\n",
      "1.0201016664505005\n",
      "0.6884275078773499\n",
      "2.7487571239471436\n",
      "0.5822367668151855\n",
      "0.3856256604194641\n",
      "1.2928543090820312\n",
      "0.50567227602005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7125205993652344\n",
      "1.2693194150924683\n",
      "0.737281084060669\n",
      "1.544362187385559\n",
      "0.732653796672821\n",
      "0.6158252954483032\n",
      "1.6790955066680908\n",
      "4.130128383636475\n",
      "0.498200923204422\n",
      "2.3803458213806152\n",
      "0.593722939491272\n",
      "1.8451266288757324\n",
      "3.191197395324707\n",
      "0.5449780821800232\n",
      "0.6674139499664307\n",
      "0.7572245001792908\n",
      "0.8805040121078491\n",
      "0.7565365433692932\n",
      "0.8900900483131409\n",
      "0.4895645081996918\n",
      "0.4885500371456146\n"
     ]
    }
   ],
   "source": [
    "ffn = load_model()\n",
    "print(ffn.x_train.shape, ffn.y_train.shape, ffn.covariates_train.shape)\n",
    "attention_size = [128] * 1\n",
    "attention_heads = [16] * 1\n",
    "print(attention_size, attention_heads)\n",
    "ffn.build_self_attention(\n",
    "    residual_connection=True,\n",
    "    aa_embedding_dim=0,\n",
    "    attention_size=attention_size,\n",
    "    use_covariates=False,\n",
    "    attention_heads=attention_heads,\n",
    "    depth_final_dense=1,\n",
    "    optimizer='adam',\n",
    "    lr=0.001,\n",
    "    loss='pois',\n",
    "    label_smoothing=0\n",
    ")\n",
    "print('built')\n",
    "EPOCHS = 2\n",
    "batch_size = 16\n",
    "print('ak to train')\n",
    "train_curve, val_curve, antigen_loss, antigen_loss_val = ffn.train(\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=batch_size,\n",
    "    log_dir='training_runs',\n",
    "    allow_early_stopping=False,\n",
    "    print_loss=True,\n",
    "    lr_schedule_factor=0.99999,\n",
    "    use_wandb=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0e86d",
   "metadata": {},
   "source": [
    "### Add WandB Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f669bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "   'method': 'grid',  # can be random, grid, bayes\n",
    "   'parameters': {\n",
    "       'lr': {  # learning rate\n",
    "           'values': [0.001, 0.005, 0.01, 0.1]\n",
    "       },\n",
    "       'aa_embedding_dim': {\n",
    "           'values': [0, 10, 26]\n",
    "       },\n",
    "       'depth_final_dense': {\n",
    "           'values': [1, 2, 3, 5, 9]\n",
    "       },\n",
    "       'model_name': {\n",
    "           'values': ['self-attention', 'bilstm', 'bigru', 'cnn']\n",
    "       },\n",
    "       # i.e., bilstm depth, SA depth, conv depth\n",
    "       'specific_layer_depth': {\n",
    "            'values': [1, 2, 3, 4, 5]\n",
    "       }\n",
    "   }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf54108-744e-4e54-83e6-68cfa9bd3798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Initialize wandb with a sample project name\n",
    "    wandb.init(project=\"TCR fitting\")\n",
    "\n",
    "    config = wandb.config\n",
    "   \n",
    "    # replace your hard-coded hyperparameters with config values\n",
    "    model_name = config.model_name\n",
    "    lr = config.lr\n",
    "    aa_embedding_dim = config.aa_embedding_dim\n",
    "    depth_final_dense = config.depth_final_dense\n",
    "    ffn = load_model()\n",
    "    print(ffn.x_train.shape, ffn.y_train.shape, ffn.covariates_train.shape)\n",
    "    if model_name.lower() == 'self-attention':\n",
    "        attention_size = [128] * config.specific_layer_depth\n",
    "        attention_heads = [16] * config.specific_layer_depth\n",
    "        print(attention_size, attention_heads)\n",
    "        ffn.build_self_attention(\n",
    "            residual_connection=True,\n",
    "            aa_embedding_dim=aa_embedding_dim,\n",
    "            attention_size=attention_size,\n",
    "            use_covariates=False,\n",
    "            attention_heads=attention_heads,\n",
    "            depth_final_dense=depth_final_dense,\n",
    "            optimizer='adam',\n",
    "            lr=lr,\n",
    "            loss='pois',\n",
    "            label_smoothing=0\n",
    "        )\n",
    "        print('built')\n",
    "    \n",
    "    elif model_name.lower() == 'bilstm':\n",
    "        topology = [32] * config.specific_layer_depth\n",
    "        ffn.build_bilstm(\n",
    "            topology=topology,\n",
    "            residual_connection=True,\n",
    "            aa_embedding_dim=aa_embedding_dim,\n",
    "            optimizer='adam',\n",
    "            lr=lr,\n",
    "            loss='pois',\n",
    "            label_smoothing=0,\n",
    "            depth_final_dense=depth_final_dense,\n",
    "            use_covariates=False,\n",
    "            one_hot_y=False,\n",
    "        )\n",
    "        print('built')\n",
    "\n",
    "    elif model_name.lower() == 'bigru':\n",
    "        topology= [10] * config.specific_layer_depth\n",
    "        ffn.build_bigru(\n",
    "            aa_embedding_dim=aa_embedding_dim,\n",
    "            residual_connection=True,\n",
    "            lr=lr,\n",
    "            loss='pois',\n",
    "        )\n",
    "        print('built')\n",
    "\n",
    "    elif model_name.lower() == 'cnn':\n",
    "        n_conv_layers = config.specific_layer_depth\n",
    "        # filter_widths = [3, 5, 3] \n",
    "        # filters = [16, 32, 64]\n",
    "        pool_sizes = [2] * n_conv_layers\n",
    "        pool_strides = [2] * n_conv_layers\n",
    "        ffn.build_conv(\n",
    "            n_conv_layers=n_conv_layers,\n",
    "            depth_final_dense=depth_final_dense,\n",
    "            # filter_widths=filter_widths,\n",
    "            # filters=filters,\n",
    "            pool_sizes=pool_sizes,\n",
    "            pool_strides=pool_strides,\n",
    "            loss='pois',\n",
    "        )\n",
    "        print('built')\n",
    "\n",
    "    # Training model\n",
    "    EPOCHS = 2\n",
    "    batch_size = 100000\n",
    "    print('ak to train')\n",
    "    train_curve, val_curve, antigen_loss, antigen_loss_val = ffn.train(\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=batch_size,\n",
    "        log_dir='training_runs',\n",
    "        allow_early_stopping=False,\n",
    "        print_loss=True,\n",
    "        lr_schedule_factor=0.99999,\n",
    "        use_wandb=True\n",
    "    )\n",
    "    # Log metrics with wandb\n",
    "    wandb.log({'Train Loss': train_curve[-1], 'Validation Loss': val_curve[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b348bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: v9p9h06w\n",
      "Sweep URL: https://wandb.ai/jmboesen/uncategorized/sweeps/v9p9h06w\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d95c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: c3vrz4eu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \taa_embedding_dim: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdepth_final_dense: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel_name: self-attention\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tspecific_layer_depth: 1\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/johnboesen/Documents/Code/#Work/tcellmatch/tutorials/wandb/run-20230721_103013-c3vrz4eu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jmboesen/uncategorized/runs/c3vrz4eu' target=\"_blank\">logical-sweep-1</a></strong> to <a href='https://wandb.ai/jmboesen/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/jmboesen/uncategorized/sweeps/v9p9h06w' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized/sweeps/v9p9h06w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jmboesen/uncategorized' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/jmboesen/uncategorized/sweeps/v9p9h06w' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized/sweeps/v9p9h06w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jmboesen/uncategorized/runs/c3vrz4eu' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized/runs/c3vrz4eu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 40, 26) (15000, 50) (15000, 2)\n",
      "[128] [16]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c8e5711ae34207ae0c3a38e71b3363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-1</strong> at: <a href='https://wandb.ai/jmboesen/uncategorized/runs/c3vrz4eu' target=\"_blank\">https://wandb.ai/jmboesen/uncategorized/runs/c3vrz4eu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230721_103013-c3vrz4eu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run c3vrz4eu errored: IndexError('tuple index out of range')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run c3vrz4eu errored: IndexError('tuple index out of range')\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcell-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
