{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to preprocess the raw data files from 10x database and feed into attention-base feed forward network for categorical classification. The introduction of 10x can be found here: https://www.10xgenomics.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-31 09:44:30.151918: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# import tensorflow as tf\n",
    "import tcellmatch.api as tm\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "#!! TODO -> remove tensorflow from venv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of input directory.\n",
    "indir = ''\n",
    "# Path to 10x raw files.\n",
    "fns = [\"vdj_v1_hs_aggregated_donor1_binarized_matrix.csv\",\n",
    "       \"vdj_v1_hs_aggregated_donor2_binarized_matrix.csv\"]\n",
    "# Path to preprocessed clonotypes files.\n",
    "fns_clonotype = [\"vdj_v1_hs_aggregated_donor1_clonotypes.csv\",\n",
    "                 \"vdj_v1_hs_aggregated_donor2_clonotypes.csv\"]\n",
    "# Path to preprocessed covariates files.\n",
    "# covariates: pd.DataFrame with covariates including TCR CDR3 sequence by cell and chain [observations, covariates]\n",
    "fns_covar = [\"vdj_v1_hs_aggregated_donor1_binarized_matrix_extended_covariates.csv\",\n",
    "             \"vdj_v1_hs_aggregated_donor2_binarized_matrix_extended_covariates.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heads of 10x raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>donor</th>\n",
       "      <th>cell_clono_cdr3_aa</th>\n",
       "      <th>cell_clono_cdr3_nt</th>\n",
       "      <th>CD3</th>\n",
       "      <th>CD19</th>\n",
       "      <th>CD45RA</th>\n",
       "      <th>CD4</th>\n",
       "      <th>CD8a</th>\n",
       "      <th>CD14</th>\n",
       "      <th>...</th>\n",
       "      <th>B0702_RPHERNGFTVL_pp65_CMV_binder</th>\n",
       "      <th>B0801_RAKFKQLL_BZLF1_EBV_binder</th>\n",
       "      <th>B0801_ELRRKMMYM_IE-1_CMV_binder</th>\n",
       "      <th>B0801_FLRGRAYGL_EBNA-3A_EBV_binder</th>\n",
       "      <th>A0101_SLEGGGLGY_NC_binder</th>\n",
       "      <th>A0101_STEGGGLAY_NC_binder</th>\n",
       "      <th>A0201_ALIAPVHAV_NC_binder</th>\n",
       "      <th>A2402_AYSSAGASI_NC_binder</th>\n",
       "      <th>B0702_GPAESAAGL_NC_binder</th>\n",
       "      <th>NR(B0801)_AAKGRGAAL_NC_binder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCTGAGACAAAGG-4</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRA:CAASVSIWTGTASKLTF;TRA:CAAWDMEYGNKLVF;TRB:C...</td>\n",
       "      <td>TRA:TGTGCAGCAAGCGTTAGTATTTGGACCGGCACTGCCAGTAAA...</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCTGAGACTGTAA-34</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRB:CASDTPVGQFF</td>\n",
       "      <td>TRB:TGTGCCAGCGATACCCCGGTTGGGCAGTTCTTC</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3485.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCTGAGAGCCCAA-5</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRA:CASYTDKLIF;TRB:CASSGGSISTDTQYF</td>\n",
       "      <td>TRA:TGTGCTTCCTACACCGACAAGCTCATCTTT;TRB:TGCGCCA...</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3383.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCTGAGAGCTGCA-24</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRB:CASSGGQSSYEQYF</td>\n",
       "      <td>TRB:TGCGCCAGCAGTGGCGGACAGAGCTCCTACGAGCAGTACTTC</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCTGAGAGGGATA-8</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRA:CAASGYGNTGRRALTF;TRB:CASSQDPAGGYNEQFF</td>\n",
       "      <td>TRA:TGTGCAGCAAGCGGGTATGGAAACACGGGCAGGAGAGCACTT...</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3427.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               barcode   donor   \n",
       "0   AAACCTGAGACAAAGG-4  donor1  \\\n",
       "1  AAACCTGAGACTGTAA-34  donor1   \n",
       "2   AAACCTGAGAGCCCAA-5  donor1   \n",
       "3  AAACCTGAGAGCTGCA-24  donor1   \n",
       "4   AAACCTGAGAGGGATA-8  donor1   \n",
       "\n",
       "                                  cell_clono_cdr3_aa   \n",
       "0  TRA:CAASVSIWTGTASKLTF;TRA:CAAWDMEYGNKLVF;TRB:C...  \\\n",
       "1                                    TRB:CASDTPVGQFF   \n",
       "2                 TRA:CASYTDKLIF;TRB:CASSGGSISTDTQYF   \n",
       "3                                 TRB:CASSGGQSSYEQYF   \n",
       "4          TRA:CAASGYGNTGRRALTF;TRB:CASSQDPAGGYNEQFF   \n",
       "\n",
       "                                  cell_clono_cdr3_nt     CD3  CD19  CD45RA   \n",
       "0  TRA:TGTGCAGCAAGCGTTAGTATTTGGACCGGCACTGCCAGTAAA...  2125.0   0.0   912.0  \\\n",
       "1              TRB:TGTGCCAGCGATACCCCGGTTGGGCAGTTCTTC  1023.0   0.0  2028.0   \n",
       "2  TRA:TGTGCTTCCTACACCGACAAGCTCATCTTT;TRB:TGCGCCA...  1598.0   3.0  3454.0   \n",
       "3     TRB:TGCGCCAGCAGTGGCGGACAGAGCTCCTACGAGCAGTACTTC   298.0   1.0   880.0   \n",
       "4  TRA:TGTGCAGCAAGCGGGTATGGAAACACGGGCAGGAGAGCACTT...  1036.0   0.0  2457.0   \n",
       "\n",
       "   CD4    CD8a  CD14  ...  B0702_RPHERNGFTVL_pp65_CMV_binder   \n",
       "0  1.0  2223.0   4.0  ...                              False  \\\n",
       "1  2.0  3485.0   1.0  ...                              False   \n",
       "2  4.0  3383.0   1.0  ...                              False   \n",
       "3  1.0  2389.0   1.0  ...                              False   \n",
       "4  2.0  3427.0   3.0  ...                              False   \n",
       "\n",
       "   B0801_RAKFKQLL_BZLF1_EBV_binder  B0801_ELRRKMMYM_IE-1_CMV_binder   \n",
       "0                            False                            False  \\\n",
       "1                            False                            False   \n",
       "2                            False                            False   \n",
       "3                            False                            False   \n",
       "4                            False                            False   \n",
       "\n",
       "   B0801_FLRGRAYGL_EBNA-3A_EBV_binder  A0101_SLEGGGLGY_NC_binder   \n",
       "0                               False                      False  \\\n",
       "1                               False                      False   \n",
       "2                               False                      False   \n",
       "3                               False                      False   \n",
       "4                               False                      False   \n",
       "\n",
       "   A0101_STEGGGLAY_NC_binder  A0201_ALIAPVHAV_NC_binder   \n",
       "0                      False                      False  \\\n",
       "1                      False                      False   \n",
       "2                      False                      False   \n",
       "3                      False                      False   \n",
       "4                      False                      False   \n",
       "\n",
       "   A2402_AYSSAGASI_NC_binder  B0702_GPAESAAGL_NC_binder   \n",
       "0                      False                      False  \\\n",
       "1                      False                      False   \n",
       "2                      False                      False   \n",
       "3                      False                      False   \n",
       "4                      False                      False   \n",
       "\n",
       "   NR(B0801)_AAKGRGAAL_NC_binder  \n",
       "0                          False  \n",
       "1                          False  \n",
       "2                          False  \n",
       "3                          False  \n",
       "4                          False  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellranger_out = pd.read_csv(fns[0])\n",
    "cellranger_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heads of 10x clonotypes files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clonotype_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>proportion</th>\n",
       "      <th>cdr3s_aa</th>\n",
       "      <th>cdr3s_nt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clonotype1</td>\n",
       "      <td>2407</td>\n",
       "      <td>0.050583</td>\n",
       "      <td>TRA:CAGHTGNQFYF;TRB:CASSWGGGSHYGYTF</td>\n",
       "      <td>TRA:TGTGCTGGTCACACCGGTAACCAGTTCTATTTT;TRB:TGTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clonotype2</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>TRA:CAARVRGFGNVLHC;TRA:CAVGDNFNKFYF;TRB:CASSLY...</td>\n",
       "      <td>TRA:TGTGCAGCAAGAGTGCGGGGCTTTGGGAATGTGCTGCATTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clonotype3</td>\n",
       "      <td>1167</td>\n",
       "      <td>0.024525</td>\n",
       "      <td>TRB:CASSWGGGSHYGYTF</td>\n",
       "      <td>TRB:TGTGCCAGCAGCTGGGGGGGCGGTAGCCACTATGGCTACACCTTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clonotype4</td>\n",
       "      <td>512</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>TRA:CAVSAASGGSYIPTF;TRB:CASSPRDRERGEQYF</td>\n",
       "      <td>TRA:TGTGCTGTGAGTGCAGCATCAGGAGGAAGCTACATACCTACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clonotype5</td>\n",
       "      <td>419</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>TRA:CAMNPAWGGATNKLIF;TRB:CSASPGDYEQYF</td>\n",
       "      <td>TRA:TGTGCAATGAACCCGGCGTGGGGTGGTGCTACAAACAAGCTC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clonotype_id  frequency  proportion   \n",
       "0   clonotype1       2407    0.050583  \\\n",
       "1   clonotype2       1244    0.026143   \n",
       "2   clonotype3       1167    0.024525   \n",
       "3   clonotype4        512    0.010760   \n",
       "4   clonotype5        419    0.008805   \n",
       "\n",
       "                                            cdr3s_aa   \n",
       "0                TRA:CAGHTGNQFYF;TRB:CASSWGGGSHYGYTF  \\\n",
       "1  TRA:CAARVRGFGNVLHC;TRA:CAVGDNFNKFYF;TRB:CASSLY...   \n",
       "2                                TRB:CASSWGGGSHYGYTF   \n",
       "3            TRA:CAVSAASGGSYIPTF;TRB:CASSPRDRERGEQYF   \n",
       "4              TRA:CAMNPAWGGATNKLIF;TRB:CSASPGDYEQYF   \n",
       "\n",
       "                                            cdr3s_nt  \n",
       "0  TRA:TGTGCTGGTCACACCGGTAACCAGTTCTATTTT;TRB:TGTG...  \n",
       "1  TRA:TGTGCAGCAAGAGTGCGGGGCTTTGGGAATGTGCTGCATTGC...  \n",
       "2  TRB:TGTGCCAGCAGCTGGGGGGGCGGTAGCCACTATGGCTACACCTTC  \n",
       "3  TRA:TGTGCTGTGAGTGCAGCATCAGGAGGAAGCTACATACCTACA...  \n",
       "4  TRA:TGTGCAATGAACCCGGCGTGGGGTGGTGCTACAAACAAGCTC...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellranger_out = pd.read_csv(fns_clonotype[0])\n",
    "cellranger_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of column names of lables to predicts in 10x raw files\n",
    "Here we take all antigens from 10x dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = [\n",
    "    'A0101_VTEHDTLLY_IE-1_CMV_binder',\n",
    "    'A0201_KTWGQYWQV_gp100_Cancer_binder',\n",
    "    'A0201_ELAGIGILTV_MART-1_Cancer_binder',\n",
    "    'A0201_CLLWSFQTSA_Tyrosinase_Cancer_binder',\n",
    "    'A0201_IMDQVPFSV_gp100_Cancer_binder',\n",
    "    'A0201_SLLMWITQV_NY-ESO-1_Cancer_binder',\n",
    "    'A0201_KVAELVHFL_MAGE-A3_Cancer_binder',\n",
    "    'A0201_KVLEYVIKV_MAGE-A1_Cancer_binder',\n",
    "    'A0201_CLLGTYTQDV_Kanamycin-B-dioxygenase_binder',\n",
    "    'A0201_LLDFVRFMGV_EBNA-3B_EBV_binder',\n",
    "    'A0201_LLMGTLGIVC_HPV-16E7_82-91_binder',\n",
    "    'A0201_CLGGLLTMV_LMP-2A_EBV_binder',\n",
    "    'A0201_YLLEMLWRL_LMP1_EBV_binder',\n",
    "    'A0201_FLYALALLL_LMP2A_EBV_binder',\n",
    "    'A0201_GILGFVFTL_Flu-MP_Influenza_binder',\n",
    "    'A0201_GLCTLVAML_BMLF1_EBV_binder',\n",
    "    'A0201_NLVPMVATV_pp65_CMV_binder',\n",
    "    'A0201_ILKEPVHGV_RT_HIV_binder',\n",
    "    'A0201_FLASKIGRLV_Ca2-indepen-Plip-A2_binder',\n",
    "    'A2402_CYTWNQMNL_WT1-(235-243)236M_Y_binder',\n",
    "    'A0201_RTLNAWVKV_Gag-protein_HIV_binder',\n",
    "    'A0201_KLQCVDLHV_PSA146-154_binder',\n",
    "    'A0201_LLFGYPVYV_HTLV-1_binder',\n",
    "    'A0201_SLFNTVATL_Gag-protein_HIV_binder',\n",
    "    'A0201_SLYNTVATLY_Gag-protein_HIV_binder',\n",
    "    'A0201_SLFNTVATLY_Gag-protein_HIV_binder',\n",
    "    'A0201_RMFPNAPYL_WT-1_binder',\n",
    "    'A0201_YLNDHLEPWI_BCL-X_Cancer_binder',\n",
    "    'A0201_MLDLQPETT_16E7_HPV_binder',\n",
    "    'A0301_KLGGALQAK_IE-1_CMV_binder',\n",
    "    'A0301_RLRAEAQVK_EMNA-3A_EBV_binder',\n",
    "    'A0301_RIAAWMATY_BCL-2L1_Cancer_binder',\n",
    "    'A1101_IVTDFSVIK_EBNA-3B_EBV_binder',\n",
    "    'A1101_AVFDRKSDAK_EBNA-3B_EBV_binder',\n",
    "    'B3501_IPSINVHHY_pp65_CMV_binder',\n",
    "    'A2402_AYAQKIFKI_IE-1_CMV_binder',\n",
    "    'A2402_QYDPVAALF_pp65_CMV_binder',\n",
    "    'B0702_QPRAPIRPI_EBNA-6_EBV_binder',\n",
    "    'B0702_TPRVTGGGAM_pp65_CMV_binder',\n",
    "    'B0702_RPPIFIRRL_EBNA-3A_EBV_binder',\n",
    "    'B0702_RPHERNGFTVL_pp65_CMV_binder',\n",
    "    'B0801_RAKFKQLL_BZLF1_EBV_binder',\n",
    "    'B0801_ELRRKMMYM_IE-1_CMV_binder',\n",
    "    'B0801_FLRGRAYGL_EBNA-3A_EBV_binder',\n",
    "    'A0101_SLEGGGLGY_NC_binder',\n",
    "    'A0101_STEGGGLAY_NC_binder',\n",
    "    'A0201_ALIAPVHAV_NC_binder',\n",
    "    'A2402_AYSSAGASI_NC_binder',\n",
    "    'B0702_GPAESAAGL_NC_binder',\n",
    "    'NR(B0801)_AAKGRGAAL_NC_binder'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of column names of negative controls in 10x raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_cols = [\n",
    "    'A0101_SLEGGGLGY_NC_binder',\n",
    "    'A0101_STEGGGLAY_NC_binder',\n",
    "    'A0201_ALIAPVHAV_NC_binder',\n",
    "    'A2402_AYSSAGASI_NC_binder',\n",
    "    'B0702_GPAESAAGL_NC_binder',\n",
    "    'NR(B0801)_AAKGRGAAL_NC_binder'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model object\n",
    "EstimatorFfn() includes all of reading, training and testing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init function doesn't use any tf, but...\n",
    "ffn = tm.models.EstimatorFfn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read 10x raw files, taking out TCR CDR3 and binarized binding matrix as training data\n",
    "We encode the TCR CDR3 amino acid sequences (include TRA and TRB) with one-hot encoding, the embedded sequences are of shape [num_samples, tra/trb, max_sequence_length, aa_onehot_dim]. For example if we take out 4000 TRB sequences seperately, the maximal length of sequences is 30 and we have 22 amino acids, the shape of output would be [4000, 1, 30, 26]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29618 clonotypes for 46526 observations in single file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1265: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19318 clonotypes for 77854 observations in single file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1365: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40500 clonotypes for 109637 observations and assigned to train data.\n"
     ]
    }
   ],
   "source": [
    "# no tf\n",
    "ffn.read_binarized_matrix(\n",
    "    fns=[indir + x for x in fns],\n",
    "    fns_clonotype=[indir + x for x in fns_clonotype],\n",
    "    fns_covar=[],\n",
    "    fn_blosum=None,\n",
    "    blosum_encoding=False,\n",
    "    is_train=True,\n",
    "    covariate_formula_categ=[\"donor\"],\n",
    "    covariate_formula_numeric=[],\n",
    "    add_non_binder_for_softmax=True,\n",
    "    chains=\"trb\",\n",
    "    label_cols=target_ids,\n",
    "    nc_cols=nc_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build training datasets\n",
    "The input consists of TCR CDR3 sequences and covariates, covariates act as a additional information which will be concatenated with TCR CDR3 sequences during training. The target set would be a binarized matrix which shows the binding between TCR CDR3 and antigens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TCR sequences:  (109637, 1, 27, 26)\n",
      "Shape of covariates:  (109637, 2)\n",
      "Shape of target set:  (109637, 51)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TCR sequences: \",ffn.x_train.shape)\n",
    "# print(\"The head of TCR sequences: \",ffn.x_train[0])\n",
    "print(\"Shape of covariates: \",ffn.covariates_train.shape)\n",
    "# print(\"The head of covariates: \",ffn.covariates_train[0:5])\n",
    "print(\"Shape of target set: \",ffn.y_train.shape)\n",
    "# print(\"The head of target set: \",ffn.y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample clonotypes to data stored in x_train\n",
    "This avoids training, evaluation or test set to be too biased to a subset of TCRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled 40500 clonotypes from 109637 cells to 40500 cells.\n"
     ]
    }
   ],
   "source": [
    "#max_obs: Maximum number of observations per clonotype.\n",
    "# * no tf\n",
    "# ffn.downsample_clonotype(max_obs=10)\n",
    "ffn.downsample_clonotype(max_obs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TCR sequences:  (40500, 1, 27, 26)\n",
      "Shape of covariates:  (40500, 2)\n",
      "Shape of target set:  (40500, 51)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TCR sequences: \",ffn.x_train.shape)\n",
    "print(\"Shape of covariates: \",ffn.covariates_train.shape)\n",
    "print(\"Shape of target set: \",ffn.y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.from_numpy(ffn.x_train)\n",
    "# torch.save(x, 'all_unique_clono.pt')\n",
    "all_labels = torch.from_numpy(ffn.y_train)\n",
    "torch.save(all_labels, 'all_clono_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40500, 51)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn.y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test dataset\n",
    "We can either split a part of training set or use a new database as the test set. Here we split test set from training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# * This is all NP, not TF\n",
    "# Clear test set.\n",
    "ffn.clear_test_data()\n",
    "ffn.sample_test_set(test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of TCR CDR3 sequences for training: \",ffn.x_train.shape)\n",
    "print(\"Shape of covariates for training: \",ffn.covariates_train.shape)\n",
    "print(\"Shape of target set for training: \",ffn.y_train.shape)\n",
    "print(\"Shape of TCR CDR3 sequences for test: \",ffn.x_test.shape)\n",
    "print(\"Shape of covariates for test: \",ffn.covariates_test.shape)\n",
    "print(\"Shape of target set for test: \",ffn.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding TCR CDR3 sequences in both training and testing set\n",
    "Since we can use TCR CDR3 in another database as test set, we should make sure they have same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no tf\n",
    "ffn.pad_sequence(target_len=40, sequence=\"tcr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of TCR CDR3 sequences for training: \",ffn.x_train.shape)\n",
    "print(\"Shape of TCR CDR3 sequences for test: \",ffn.x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample data to given number of observations.\n",
    "In order to save time we sample a small dataset for training. Never use this method in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of TCR CDR3 sequences for training: \",ffn.x_train.shape)\n",
    "print(\"Shape of TCR CDR3 sequences for test: \",ffn.x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez_compressed(\n",
    "    \"ffn_data.npz\",\n",
    "    x_train=ffn.x_train,\n",
    "    covariates_train=ffn.covariates_train,\n",
    "    y_train=ffn.y_train,\n",
    "    x_test=ffn.x_test,\n",
    "    covariates_test=ffn.covariates_test,\n",
    "    y_test=ffn.y_test,\n",
    "    clone_train=ffn.clone_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a attention-based feed forward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.build_bilstm(\n",
    "    topology = [10, 10],\n",
    "    residual_connection=True,\n",
    "    aa_embedding_dim=0,\n",
    "    optimizer='adam',\n",
    "    lr=0.001,\n",
    "    loss='cce',\n",
    "    label_smoothing=0,\n",
    "    use_covariates=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "Train this model for 1 epoch       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.save_idx('SAVED_IDX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ffn.train(\n",
    "    epochs=10,\n",
    "    batch_size=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('saved_model', exist_ok=True)\n",
    "ffn.save_model_full('saved_model', save_yhat=False, save_train_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(ffn.model, input_size=[ffn.x_train[0].shape, ffn.covariates_train[0].shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce evaluation in a new instance of model that receives same weights"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ffn2 = tm.models.EstimatorFfn()\n",
    "ffn2.load_model_full(fn='saved_model')\n",
    "print(ffn2.evaluate(test_only=True))\n",
    "ffn2.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcell-env",
   "language": "python",
   "name": "tcell-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
