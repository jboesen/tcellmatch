{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10X `tcellmatch` Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to preprocess the raw data files from 10x database and feed into a feed forward network for categorical classification. The introduction of 10x can be found here: https://www.10xgenomics.com\n",
    "\n",
    "The task of this model is based on [this paper](https://www.embopress.org/doi/full/10.15252/msb.20199416), but, in brief, it approximates CDR3 RNA sequences to antigen specificity. This antigen specificity can further be predicted as either number of bindings or max bindings for each sequence.\n",
    "\n",
    "The architecture of the models are as follows\n",
    "\n",
    "## BiLSTM\n",
    "\n",
    "- Input Layer: n x (alpha/beta chain dimension) x CDR3 sequence length x one-hot encoding for each amino acid; here, the shape is `n x 1 x 40 x 26`\n",
    "\n",
    "- Hidden Layers:\n",
    "    1. **Embedding Layer**: An optional 1x1 convolutional layer which is used to create lower-dimensional embeddings of one-hot encoded amino acids before the sequence model is applied. The size of the embedding can be configured using the `aa_embedding_dim` parameter.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, aa_embedding_dim)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    2. **Bi-directional Recurrent Layers**: A sequence of BiLSTM or BiGRU layers (configured via the `model` parameter), with a user-specified number of layers and dimensions. These layers process the sequence data and provide capability to capture complex temporal dependencies.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "    3. **Reshaping Layer**: The output from the BiLSTM/BiGRU layers is reshaped to be 2D in preparation for the fully connected layers, and non-sequence covariates, if provided, are concatenated with the sequence-derived representations.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "        Output Shape: (batch_size, hidden_size * 2 \\[+ hidden_size * 2 if split\\] + num_covariates)\n",
    "\n",
    "    4. **Dense Layers**: A user-specified number of final fully connected layers (`depth_final_dense`) are used for the final task-specific prediction.\n",
    "\n",
    "        Input Shape: (batch_size, hidden_size * 2 \\[+ hidden_size * 2 if split\\] + num_covariates)\n",
    "\n",
    "        Output Shape: (batch_size, labels_dim)\n",
    "\n",
    "\n",
    "- Activation: ReLU or Softmax depending on task\n",
    "\n",
    "## Self-Attention\n",
    "\n",
    "- Input Layer: n x (alpha/beta chain dimension) x CDR3 sequence length x one-hot encoding for each amino acid; here, the shape is ``n x 1 x 40 x 26``\n",
    "- Hidden Layers:\n",
    "    1. **Embedding Layer**: An optional 1x1 convolutional layer which is used to create lower-dimensional embeddings of one-hot encoded amino acids before the sequence model is applied. The size of the embedding can be configured using the `aa_embedding_dim` parameter.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, aa_embedding_dim)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length, attention_size)\n",
    "\n",
    "    2. **Reshaping Layer**: The output from the self-attention layers is reshaped to be 2D in preparation for the fully connected layers, and non-sequence covariates, if provided, are concatenated with the sequence-derived representations\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, attention_size)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length * attention_size + num_covariates)\n",
    "    3. **Dense Layers**: A user-specified number of final fully connected layers (`depth_final_dense`) are used for the final task-specific prediction. \n",
    "\n",
    "        Input Shape: (batch_size, sequence_length * attention_size + num_covariates)\n",
    "\n",
    "        Output Shape: (batch_size, labels_dim)\n",
    "\n",
    "- Activation: ReLU or Softmax depending on task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 15:28:09.969421: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtm\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pritn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/api/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/api/models.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EstimatorFfn, EstimatorBinary\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_base\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EstimatorBase\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_binary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EstimatorBinary\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_ffn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EstimatorFfn\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madditional_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deviation_label, deviation_global, auc_label, auc_global, pr_label, pr_global\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_binary.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_ffn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EstimatorFfn\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEstimatorBinary\u001b[39;00m(EstimatorFfn):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_custom_any\u001b[39m(\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m             yhat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m             transform_flavour: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     ):\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_ffn.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels_ffn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelBiRnn, ModelSa, ModelConv, ModelLinear, ModelNoseq\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_inception\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelInception\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madditional_metrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pr_global, pr_label, auc_global, auc_label, \\\n\u001b[1;32m     24\u001b[0m     deviation_global, deviation_label\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/models/models_ffn.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pylint: disable=E1101\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# pylint: disable=C0302\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# pylint: disable=C0301\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# pylint: disable=C0114\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# pylint: disable=C0103\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List, Union\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_aa_embedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerAaEmbedding\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerMultiheadSelfAttention\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtcellmatch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerConv\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/models/layers/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerConv\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_inception\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LayerInception\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayer_stack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_layer_set\n",
      "File \u001b[0;32m~/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/models/layers/layer_stack.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# import functools\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from typing import List, Tuple\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# # import tensorflow as tf\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# !! TODO: not implemented in torch\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_layer_set\u001b[39m(\n\u001b[0;32m----> 8\u001b[0m         layer_types: \u001b[43mList\u001b[49m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m      9\u001b[0m         activations: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     10\u001b[0m         filter_widths: List[Tuple],\n\u001b[1;32m     11\u001b[0m         widths: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m     12\u001b[0m         strides: List[Tuple],\n\u001b[1;32m     13\u001b[0m         dropout_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;66;03m# dtype=tf.float32\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     16\u001b[0m ):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#     \"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#     Build a sub-network as a callable function.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#     # net = tf.keras.Sequential(net)\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m#     return net\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print('a')\n",
    "import tcellmatch.api as tm\n",
    "pritn('b')\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pytorch_model_summary import summary\n",
    "from torchmetrics import Accuracy\n",
    "import torch\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data below:\n",
    "\n",
    "https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-1-1-standard-3-0-2\n",
    "\n",
    "https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-2-1-standard-3-0-2\n",
    "\n",
    "For each donor, the binarized matrix corresponds to \"binarized matrix CSV\" on 10X and the clonotype matrix corresponds to \"VDJ - Clonotype info (CSV)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of input directory.\n",
    "indir = '../tutorial_data/'\n",
    "# Path to 10x raw files.\n",
    "fns = [f\"{indir}vdj_v1_hs_aggregated_donor1_binarized_matrix.csv\",\n",
    "       f\"{indir}vdj_v1_hs_aggregated_donor2_binarized_matrix.csv\"]\n",
    "# Path to preprocessed clonotypes files.\n",
    "fns_clonotype = [f\"{indir}vdj_v1_hs_aggregated_donor1_clonotypes.csv\",\n",
    "                 f\"{indir}vdj_v1_hs_aggregated_donor2_clonotypes.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellranger_out = pd.read_csv(fns[0])\n",
    "cellranger_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cellranger_out\n",
    "column_names = data.columns\n",
    "column_types = data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellranger_out = pd.read_csv(fns_clonotype[0])\n",
    "cellranger_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of column names of labels to predict in 10x raw files\n",
    "Here we take all antigens from 10x dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = [\n",
    "    'A0101_VTEHDTLLY_IE-1_CMV_binder',\n",
    "    'A0201_KTWGQYWQV_gp100_Cancer_binder',\n",
    "    'A0201_ELAGIGILTV_MART-1_Cancer_binder',\n",
    "    'A0201_CLLWSFQTSA_Tyrosinase_Cancer_binder',\n",
    "    'A0201_IMDQVPFSV_gp100_Cancer_binder',\n",
    "    'A0201_SLLMWITQV_NY-ESO-1_Cancer_binder',\n",
    "    'A0201_KVAELVHFL_MAGE-A3_Cancer_binder',\n",
    "    'A0201_KVLEYVIKV_MAGE-A1_Cancer_binder',\n",
    "    'A0201_CLLGTYTQDV_Kanamycin-B-dioxygenase_binder',\n",
    "    'A0201_LLDFVRFMGV_EBNA-3B_EBV_binder',\n",
    "    'A0201_LLMGTLGIVC_HPV-16E7_82-91_binder',\n",
    "    'A0201_CLGGLLTMV_LMP-2A_EBV_binder',\n",
    "    'A0201_YLLEMLWRL_LMP1_EBV_binder',\n",
    "    'A0201_FLYALALLL_LMP2A_EBV_binder',\n",
    "    'A0201_GILGFVFTL_Flu-MP_Influenza_binder',\n",
    "    'A0201_GLCTLVAML_BMLF1_EBV_binder',\n",
    "    'A0201_NLVPMVATV_pp65_CMV_binder',\n",
    "    'A0201_ILKEPVHGV_RT_HIV_binder',\n",
    "    'A0201_FLASKIGRLV_Ca2-indepen-Plip-A2_binder',\n",
    "    'A2402_CYTWNQMNL_WT1-(235-243)236M_Y_binder',\n",
    "    'A0201_RTLNAWVKV_Gag-protein_HIV_binder',\n",
    "    'A0201_KLQCVDLHV_PSA146-154_binder',\n",
    "    'A0201_LLFGYPVYV_HTLV-1_binder',\n",
    "    'A0201_SLFNTVATL_Gag-protein_HIV_binder',\n",
    "    'A0201_SLYNTVATLY_Gag-protein_HIV_binder',\n",
    "    'A0201_SLFNTVATLY_Gag-protein_HIV_binder',\n",
    "    'A0201_RMFPNAPYL_WT-1_binder',\n",
    "    'A0201_YLNDHLEPWI_BCL-X_Cancer_binder',\n",
    "    'A0201_MLDLQPETT_16E7_HPV_binder',\n",
    "    'A0301_KLGGALQAK_IE-1_CMV_binder',\n",
    "    'A0301_RLRAEAQVK_EMNA-3A_EBV_binder',\n",
    "    'A0301_RIAAWMATY_BCL-2L1_Cancer_binder',\n",
    "    'A1101_IVTDFSVIK_EBNA-3B_EBV_binder',\n",
    "    'A1101_AVFDRKSDAK_EBNA-3B_EBV_binder',\n",
    "    'B3501_IPSINVHHY_pp65_CMV_binder',\n",
    "    'A2402_AYAQKIFKI_IE-1_CMV_binder',\n",
    "    'A2402_QYDPVAALF_pp65_CMV_binder',\n",
    "    'B0702_QPRAPIRPI_EBNA-6_EBV_binder',\n",
    "    'B0702_TPRVTGGGAM_pp65_CMV_binder',\n",
    "    'B0702_RPPIFIRRL_EBNA-3A_EBV_binder',\n",
    "    'B0702_RPHERNGFTVL_pp65_CMV_binder',\n",
    "    'B0801_RAKFKQLL_BZLF1_EBV_binder',\n",
    "    'B0801_ELRRKMMYM_IE-1_CMV_binder',\n",
    "    'B0801_FLRGRAYGL_EBNA-3A_EBV_binder',\n",
    "    'A0101_SLEGGGLGY_NC_binder',\n",
    "    'A0101_STEGGGLAY_NC_binder',\n",
    "    'A0201_ALIAPVHAV_NC_binder',\n",
    "    'A2402_AYSSAGASI_NC_binder',\n",
    "    'B0702_GPAESAAGL_NC_binder',\n",
    "    'NR(B0801)_AAKGRGAAL_NC_binder'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of column names of negative controls in 10x raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_cols = [\n",
    "    'A0101_SLEGGGLGY_NC_binder',\n",
    "    'A0101_STEGGGLAY_NC_binder',\n",
    "    'A0201_ALIAPVHAV_NC_binder',\n",
    "    'A2402_AYSSAGASI_NC_binder',\n",
    "    'B0702_GPAESAAGL_NC_binder',\n",
    "    'NR(B0801)_AAKGRGAAL_NC_binder'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Use these if you want binding counts instead of top binder categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BIND_COUNTS = False\n",
    "\n",
    "if USE_BIND_COUNTS:\n",
    "    target_ids = [\n",
    "        'A0101_VTEHDTLLY_IE-1_CMV',\n",
    "        'A0201_KTWGQYWQV_gp100_Cancer',\n",
    "        'A0201_ELAGIGILTV_MART-1_Cancer',\n",
    "        'A0201_CLLWSFQTSA_Tyrosinase_Cancer',\n",
    "        'A0201_IMDQVPFSV_gp100_Cancer',\n",
    "        'A0201_SLLMWITQV_NY-ESO-1_Cancer',\n",
    "        'A0201_KVAELVHFL_MAGE-A3_Cancer',\n",
    "        'A0201_KVLEYVIKV_MAGE-A1_Cancer',\n",
    "        'A0201_CLLGTYTQDV_Kanamycin-B-dioxygenase',\n",
    "        'A0201_LLDFVRFMGV_EBNA-3B_EBV',\n",
    "        'A0201_LLMGTLGIVC_HPV-16E7_82-91',\n",
    "        'A0201_CLGGLLTMV_LMP-2A_EBV',\n",
    "        'A0201_YLLEMLWRL_LMP1_EBV',\n",
    "        'A0201_FLYALALLL_LMP2A_EBV',\n",
    "        'A0201_GILGFVFTL_Flu-MP_Influenza',\n",
    "        'A0201_GLCTLVAML_BMLF1_EBV',\n",
    "        'A0201_NLVPMVATV_pp65_CMV',\n",
    "        'A0201_ILKEPVHGV_RT_HIV',\n",
    "        'A0201_FLASKIGRLV_Ca2-indepen-Plip-A2',\n",
    "        'A2402_CYTWNQMNL_WT1-(235-243)236M_Y',\n",
    "        'A0201_RTLNAWVKV_Gag-protein_HIV',\n",
    "        'A0201_KLQCVDLHV_PSA146-154',\n",
    "        'A0201_LLFGYPVYV_HTLV-1',\n",
    "        'A0201_SLFNTVATL_Gag-protein_HIV',\n",
    "        'A0201_SLYNTVATLY_Gag-protein_HIV',\n",
    "        'A0201_SLFNTVATLY_Gag-protein_HIV',\n",
    "        'A0201_RMFPNAPYL_WT-1',\n",
    "        'A0201_YLNDHLEPWI_BCL-X_Cancer',\n",
    "        'A0201_MLDLQPETT_16E7_HPV',\n",
    "        'A0301_KLGGALQAK_IE-1_CMV',\n",
    "        'A0301_RLRAEAQVK_EMNA-3A_EBV',\n",
    "        'A0301_RIAAWMATY_BCL-2L1_Cancer',\n",
    "        'A1101_IVTDFSVIK_EBNA-3B_EBV',\n",
    "        'A1101_AVFDRKSDAK_EBNA-3B_EBV',\n",
    "        'B3501_IPSINVHHY_pp65_CMV',\n",
    "        'A2402_AYAQKIFKI_IE-1_CMV',\n",
    "        'A2402_QYDPVAALF_pp65_CMV',\n",
    "        'B0702_QPRAPIRPI_EBNA-6_EBV',\n",
    "        'B0702_TPRVTGGGAM_pp65_CMV',\n",
    "        'B0702_RPPIFIRRL_EBNA-3A_EBV',\n",
    "        'B0702_RPHERNGFTVL_pp65_CMV',\n",
    "        'B0801_RAKFKQLL_BZLF1_EBV',\n",
    "        'B0801_ELRRKMMYM_IE-1_CMV',\n",
    "        'B0801_FLRGRAYGL_EBNA-3A_EBV',\n",
    "        'A0101_SLEGGGLGY_NC',\n",
    "        'A0101_STEGGGLAY_NC',\n",
    "        'A0201_ALIAPVHAV_NC',\n",
    "        'A2402_AYSSAGASI_NC',\n",
    "        'B0702_GPAESAAGL_NC',\n",
    "        'NR(B0801)_AAKGRGAAL_NC',\n",
    "    ]\n",
    "    nc_cols = [\n",
    "        'A0101_SLEGGGLGY_NC',\n",
    "        'A0101_STEGGGLAY_NC',\n",
    "        'A0201_ALIAPVHAV_NC',\n",
    "        'A2402_AYSSAGASI_NC',\n",
    "        'B0702_GPAESAAGL_NC',\n",
    "        'NR(B0801)_AAKGRGAAL_NC'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model object\n",
    "EstimatorFfn() includes all of reading, training and testing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = tm.models.EstimatorFfn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read 10x raw files, taking out TCR CDR3 and binarized binding matrix as training data\n",
    "We encode the TCR CDR3 amino acid sequences (include TRA and TRB) with one-hot encoding, the embedded sequences are of shape [num_samples, tra/trb, max_sequence_length, aa_onehot_dim]. For example if we take out 4000 TRB sequences seperately, the maximal length of sequences is 30 and we have 22 amino acids, the shape of output would be [4000, 1, 30, 26]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.read_binarized_matrix(\n",
    "    fns=[indir + x for x in fns],\n",
    "    fns_clonotype=[indir + x for x in fns_clonotype],\n",
    "    fns_covar=[],\n",
    "    fn_blosum=f\"{indir}BLOSUM50.csv\",\n",
    "    blosum_encoding=False,\n",
    "    is_train=True,\n",
    "    # include categorical variable for which donor we get from\n",
    "    covariate_formula_categ=[\"donor\"],\n",
    "    covariate_formula_numeric=[],\n",
    "    # Whether to add an additional non-binder category for softmax activation function\n",
    "    add_non_binder_for_softmax=False,\n",
    "    # we are only keeping trb chain\n",
    "    chains=\"trb\",\n",
    "    label_cols=target_ids,\n",
    "    nc_cols=nc_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input consists of TCR CDR3 sequences and covariates. Covariates act as a additional information which will be concatenated with TCR CDR3 sequences during training. The target set is a binarized matrix which shows the binding between TCR CDR3 and antigens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of TCR sequences: \",ffn.x_train.shape)\n",
    "# print(\"The head of TCR sequences: \",ffn.x_train[0])\n",
    "print(\"Shape of covariates: \",ffn.covariates_train.shape)\n",
    "# print(\"The head of covariates: \",ffn.covariates_train[0:5])\n",
    "print(\"Shape of target set: \",ffn.y_train.shape)\n",
    "# print(\"The head of target set: \",ffn.y_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample clonotypes to data stored in x_train\n",
    "This avoids training, evaluation or test set being too biased toward a subset of TCRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_obs: Maximum number of observations per clonotype.\n",
    "ffn.downsample_clonotype(max_obs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of TCR sequences: \",ffn.x_train.shape)\n",
    "print(\"Shape of covariates: \",ffn.covariates_train.shape)\n",
    "print(\"Shape of target set: \",ffn.y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test dataset\n",
    "We can either split the training set or use a new database as the test set. Here, we split test set from training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.clear_test_data()\n",
    "ffn.sample_test_set(test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of TCR CDR3 sequences for training: \",ffn.x_train.shape)\n",
    "print(\"Shape of covariates for training: \",ffn.covariates_train.shape)\n",
    "print(\"Shape of target set for training: \",ffn.y_train.shape)\n",
    "print(\"Shape of TCR CDR3 sequences for test: \",ffn.x_test.shape)\n",
    "print(\"Shape of covariates for test: \",ffn.covariates_test.shape)\n",
    "print(\"Shape of target set for test: \",ffn.y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding TCR CDR3 sequences in both training and testing set\n",
    "Since we can use TCR CDR3 in another database as the test set, we should make sure they have same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.pad_sequence(target_len=40, sequence=\"tcr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample data to given number of observations.\n",
    "In order to save time, we sample a small dataset for training. Never use this method in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.downsample_data(n=200, data=\"train\")\n",
    "ffn.downsample_data(n=200, data=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of TCR CDR3 sequences for training: \",ffn.x_train.shape)\n",
    "print(\"Shape of TCR CDR3 sequences for test: \",ffn.x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save imported data as NumPy Arrays (optional)\n",
    "This can be useful if you want to avoid binarizing when debugging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_TO_NUMPY = True\n",
    "if SAVE_TO_NUMPY:\n",
    "    np.savez_compressed(\n",
    "        f\"{indir}ffn_data_categ.npz\",\n",
    "        x_train=ffn.x_train,\n",
    "        covariates_train=ffn.covariates_train,\n",
    "        y_train=ffn.y_train,\n",
    "        x_test=ffn.x_test,\n",
    "        covariates_test=ffn.covariates_test,\n",
    "        y_test=ffn.y_test,\n",
    "        clone_train=ffn.clone_train\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "Here, we can build two models: a BiLSTM-based or self-attention-based model, detailed above.\n",
    "\n",
    "Loss has the following possible parameters\n",
    "\n",
    "1. Discrete\n",
    "    1. Binary Crossentropy (param \"bce\")\n",
    "    2. Weighted Binary Crossentropy (param \"wbce\")\n",
    "    3. Categorical Crossentropy (param \"cce\")\n",
    "2. Continuous\n",
    "    1. MMD (param \"mmd\")\n",
    "    2. Mean Squared error (param \"mse\")\n",
    "    3. Poisson (param \"pois\")\n",
    "    \n",
    "Calling one of these creates the model and sets the ffn.model attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SELF_ATTENTION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SELF_ATTENTION:\n",
    "    ffn.build_self_attention(\n",
    "        residual_connection=True,\n",
    "        aa_embedding_dim=0,\n",
    "        # hidden size of each attention layer\n",
    "        attention_size=[5, 5],\n",
    "        # number of heads at each layer\n",
    "        attention_heads=[4, 4],\n",
    "        optimizer='adam',\n",
    "        lr=0.001,\n",
    "        loss='mmd' if USE_BIND_COUNTS else 'wbce',\n",
    "        label_smoothing=0\n",
    "    )\n",
    "else:\n",
    "    ffn.build_bilstm(\n",
    "        # The depth of each bilstm layer (length of feature vector)\n",
    "        topology = [10, 10],\n",
    "        residual_connection=True,\n",
    "        # Dimension of the linear amino acid embedding, ie number of 1x1 convolutional filters.\n",
    "        # set to input dimension if aa_embedding_dim==0.\n",
    "        aa_embedding_dim=0,\n",
    "        optimizer='adam',\n",
    "        lr=0.001,\n",
    "        loss='pois' if USE_BIND_COUNTS else 'wcbe',\n",
    "        label_smoothing=0,\n",
    "        # whether to assume covariates in model architecture\n",
    "        use_covariates=False,\n",
    "        # whether we are predicting max binding categorical\n",
    "        # or binding counts\n",
    "        one_hot_y=not USE_BIND_COUNTS\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "Train this model for 2 epochs     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "\n",
    "train_curve, val_curve = ffn.train(\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=8,\n",
    "    # tensorboard logs to this directory\n",
    "    log_dir='training_runs',\n",
    "    # if true, saves epochs x n_classes as ffn.antigen_loss\n",
    "    # ijth element is loss of ith epoch on jth antigen\n",
    "    save_antigen_loss=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to get the ouputs before our linear layer and store them for other use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.model.get_embeddings(torch.ones(1, 1, 40, 26)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set\n",
    "This evaluates the data and returns binary and custom (i.e., based on how the model was built above) loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('saved_model', exist_ok=True)\n",
    "# save_yhat means save predictions\n",
    "ffn.save_model_full('saved_model', save_yhat=False, save_train_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate/Compare the Model\n",
    "We predict the labels on test data and store to `ffn.predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.predict()\n",
    "ffn.predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Confusion Matrix\n",
    "This is only applicable, of course, if you've used the one-hot encoded maximum binding y-data. If it is, you can use this to also compare with the original tcellmatch in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_BIND_COUNTS:\n",
    "    true_labels = np.argmax(ffn.y_test, axis=1)\n",
    "    predicted_labels = np.argmax(ffn.predictions, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce evaluation in a new instance of model w/ same weights\n",
    "\n",
    "We load the model, with weights and data included, and evaluate and predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn2 = tm.models.EstimatorFfn()\n",
    "ffn2.load_model_full(fn='saved_model')\n",
    "print(ffn2.evaluate(test_only=True))\n",
    "ffn2.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcell-env",
   "language": "python",
   "name": "tcell-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
