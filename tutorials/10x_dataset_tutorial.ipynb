{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10X `tcellmatch` Tutorial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to preprocess the raw data files from 10x database and feed into a feed forward network for categorical classification. The introduction of 10x can be found here: https://www.10xgenomics.com\n",
    "\n",
    "The task of this model is based on [this paper](https://www.embopress.org/doi/full/10.15252/msb.20199416), but, in brief, it approximates CDR3 RNA sequences to antigen specificity. This antigen specificity can further be predicted as either number of bindings or max bindings for each sequence.\n",
    "\n",
    "The architecture of the models are as follows\n",
    "\n",
    "## BiLSTM\n",
    "\n",
    "- Input Layer: n x (alpha/beta chain dimension) x CDR3 sequence length x one-hot encoding for each amino acid; here, the shape is `n x 1 x 40 x 26`\n",
    "\n",
    "- Hidden Layers:\n",
    "    1. **Embedding Layer**: An optional 1x1 convolutional layer which is used to create lower-dimensional embeddings of one-hot encoded amino acids before the sequence model is applied. The size of the embedding can be configured using the `aa_embedding_dim` parameter.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, aa_embedding_dim)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "    2. **Bi-directional Recurrent Layers**: A sequence of BiLSTM or BiGRU layers (configured via the `model` parameter), with a user-specified number of layers and dimensions. These layers process the sequence data and provide capability to capture complex temporal dependencies.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "    3. **Reshaping Layer**: The output from the BiLSTM/BiGRU layers is reshaped to be 2D in preparation for the fully connected layers, and non-sequence covariates, if provided, are concatenated with the sequence-derived representations.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, hidden_size)\n",
    "\n",
    "        Output Shape: (batch_size, hidden_size * 2 \\[+ hidden_size * 2 if split\\] + num_covariates)\n",
    "\n",
    "    4. **Dense Layers**: A user-specified number of final fully connected layers (`depth_final_dense`) are used for the final task-specific prediction.\n",
    "\n",
    "        Input Shape: (batch_size, hidden_size * 2 \\[+ hidden_size * 2 if split\\] + num_covariates)\n",
    "\n",
    "        Output Shape: (batch_size, labels_dim)\n",
    "\n",
    "\n",
    "- Activation: ReLU or Softmax depending on task\n",
    "\n",
    "## Self-Attention\n",
    "\n",
    "- Input Layer: n x (alpha/beta chain dimension) x CDR3 sequence length x one-hot encoding for each amino acid; here, the shape is ``n x 1 x 40 x 26``\n",
    "- Hidden Layers:\n",
    "    1. **Embedding Layer**: An optional 1x1 convolutional layer which is used to create lower-dimensional embeddings of one-hot encoded amino acids before the sequence model is applied. The size of the embedding can be configured using the `aa_embedding_dim` parameter.\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, aa_embedding_dim)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length, attention_size)\n",
    "\n",
    "    2. **Reshaping Layer**: The output from the self-attention layers is reshaped to be 2D in preparation for the fully connected layers, and non-sequence covariates, if provided, are concatenated with the sequence-derived representations\n",
    "\n",
    "        Input Shape: (batch_size, sequence_length, attention_size)\n",
    "\n",
    "        Output Shape: (batch_size, sequence_length * attention_size + num_covariates)\n",
    "    3. **Dense Layers**: A user-specified number of final fully connected layers (`depth_final_dense`) are used for the final task-specific prediction. \n",
    "\n",
    "        Input Shape: (batch_size, sequence_length * attention_size + num_covariates)\n",
    "\n",
    "        Output Shape: (batch_size, labels_dim)\n",
    "\n",
    "- Activation: ReLU or Softmax depending on task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tcellmatch.api as tm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pytorch_model_summary import summary\n",
    "from torchmetrics import Accuracy\n",
    "import torch\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data Directories"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the data below:\n",
    "\n",
    "https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-1-1-standard-3-0-2\n",
    "\n",
    "https://www.10xgenomics.com/resources/datasets/cd-8-plus-t-cells-of-healthy-donor-2-1-standard-3-0-2\n",
    "\n",
    "For each donor, the binarized matrix corresponds to \"binarized matrix CSV\" on 10X and the clonotype matrix corresponds to \"VDJ - Clonotype info (CSV)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of input directory.\n",
    "indir = '../tutorial_data/'\n",
    "# Path to 10x raw files.\n",
    "fns = [f\"{indir}vdj_v1_hs_aggregated_donor1_binarized_matrix.csv\",\n",
    "       f\"{indir}vdj_v1_hs_aggregated_donor2_binarized_matrix.csv\"]\n",
    "# Path to preprocessed clonotypes files.\n",
    "fns_clonotype = [f\"{indir}vdj_v1_hs_aggregated_donor1_clonotypes.csv\",\n",
    "                 f\"{indir}vdj_v1_hs_aggregated_donor2_clonotypes.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>donor</th>\n",
       "      <th>cell_clono_cdr3_aa</th>\n",
       "      <th>cell_clono_cdr3_nt</th>\n",
       "      <th>CD3</th>\n",
       "      <th>CD19</th>\n",
       "      <th>CD45RA</th>\n",
       "      <th>CD4</th>\n",
       "      <th>CD8a</th>\n",
       "      <th>CD14</th>\n",
       "      <th>...</th>\n",
       "      <th>B0702_RPHERNGFTVL_pp65_CMV_binder</th>\n",
       "      <th>B0801_RAKFKQLL_BZLF1_EBV_binder</th>\n",
       "      <th>B0801_ELRRKMMYM_IE-1_CMV_binder</th>\n",
       "      <th>B0801_FLRGRAYGL_EBNA-3A_EBV_binder</th>\n",
       "      <th>A0101_SLEGGGLGY_NC_binder</th>\n",
       "      <th>A0101_STEGGGLAY_NC_binder</th>\n",
       "      <th>A0201_ALIAPVHAV_NC_binder</th>\n",
       "      <th>A2402_AYSSAGASI_NC_binder</th>\n",
       "      <th>B0702_GPAESAAGL_NC_binder</th>\n",
       "      <th>NR(B0801)_AAKGRGAAL_NC_binder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACCTGAGACAAAGG-4</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRA:CAASVSIWTGTASKLTF;TRA:CAAWDMEYGNKLVF;TRB:C...</td>\n",
       "      <td>TRA:TGTGCAGCAAGCGTTAGTATTTGGACCGGCACTGCCAGTAAA...</td>\n",
       "      <td>2125.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACCTGAGACTGTAA-34</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRB:CASDTPVGQFF</td>\n",
       "      <td>TRB:TGTGCCAGCGATACCCCGGTTGGGCAGTTCTTC</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2028.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3485.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACCTGAGAGCCCAA-5</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRA:CASYTDKLIF;TRB:CASSGGSISTDTQYF</td>\n",
       "      <td>TRA:TGTGCTTCCTACACCGACAAGCTCATCTTT;TRB:TGCGCCA...</td>\n",
       "      <td>1598.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3383.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACCTGAGAGCTGCA-24</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRB:CASSGGQSSYEQYF</td>\n",
       "      <td>TRB:TGCGCCAGCAGTGGCGGACAGAGCTCCTACGAGCAGTACTTC</td>\n",
       "      <td>298.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2389.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACCTGAGAGGGATA-8</td>\n",
       "      <td>donor1</td>\n",
       "      <td>TRA:CAASGYGNTGRRALTF;TRB:CASSQDPAGGYNEQFF</td>\n",
       "      <td>TRA:TGTGCAGCAAGCGGGTATGGAAACACGGGCAGGAGAGCACTT...</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2457.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3427.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               barcode   donor   \n",
       "0   AAACCTGAGACAAAGG-4  donor1  \\\n",
       "1  AAACCTGAGACTGTAA-34  donor1   \n",
       "2   AAACCTGAGAGCCCAA-5  donor1   \n",
       "3  AAACCTGAGAGCTGCA-24  donor1   \n",
       "4   AAACCTGAGAGGGATA-8  donor1   \n",
       "\n",
       "                                  cell_clono_cdr3_aa   \n",
       "0  TRA:CAASVSIWTGTASKLTF;TRA:CAAWDMEYGNKLVF;TRB:C...  \\\n",
       "1                                    TRB:CASDTPVGQFF   \n",
       "2                 TRA:CASYTDKLIF;TRB:CASSGGSISTDTQYF   \n",
       "3                                 TRB:CASSGGQSSYEQYF   \n",
       "4          TRA:CAASGYGNTGRRALTF;TRB:CASSQDPAGGYNEQFF   \n",
       "\n",
       "                                  cell_clono_cdr3_nt     CD3  CD19  CD45RA   \n",
       "0  TRA:TGTGCAGCAAGCGTTAGTATTTGGACCGGCACTGCCAGTAAA...  2125.0   0.0   912.0  \\\n",
       "1              TRB:TGTGCCAGCGATACCCCGGTTGGGCAGTTCTTC  1023.0   0.0  2028.0   \n",
       "2  TRA:TGTGCTTCCTACACCGACAAGCTCATCTTT;TRB:TGCGCCA...  1598.0   3.0  3454.0   \n",
       "3     TRB:TGCGCCAGCAGTGGCGGACAGAGCTCCTACGAGCAGTACTTC   298.0   1.0   880.0   \n",
       "4  TRA:TGTGCAGCAAGCGGGTATGGAAACACGGGCAGGAGAGCACTT...  1036.0   0.0  2457.0   \n",
       "\n",
       "   CD4    CD8a  CD14  ...  B0702_RPHERNGFTVL_pp65_CMV_binder   \n",
       "0  1.0  2223.0   4.0  ...                              False  \\\n",
       "1  2.0  3485.0   1.0  ...                              False   \n",
       "2  4.0  3383.0   1.0  ...                              False   \n",
       "3  1.0  2389.0   1.0  ...                              False   \n",
       "4  2.0  3427.0   3.0  ...                              False   \n",
       "\n",
       "   B0801_RAKFKQLL_BZLF1_EBV_binder  B0801_ELRRKMMYM_IE-1_CMV_binder   \n",
       "0                            False                            False  \\\n",
       "1                            False                            False   \n",
       "2                            False                            False   \n",
       "3                            False                            False   \n",
       "4                            False                            False   \n",
       "\n",
       "   B0801_FLRGRAYGL_EBNA-3A_EBV_binder  A0101_SLEGGGLGY_NC_binder   \n",
       "0                               False                      False  \\\n",
       "1                               False                      False   \n",
       "2                               False                      False   \n",
       "3                               False                      False   \n",
       "4                               False                      False   \n",
       "\n",
       "   A0101_STEGGGLAY_NC_binder  A0201_ALIAPVHAV_NC_binder   \n",
       "0                      False                      False  \\\n",
       "1                      False                      False   \n",
       "2                      False                      False   \n",
       "3                      False                      False   \n",
       "4                      False                      False   \n",
       "\n",
       "   A2402_AYSSAGASI_NC_binder  B0702_GPAESAAGL_NC_binder   \n",
       "0                      False                      False  \\\n",
       "1                      False                      False   \n",
       "2                      False                      False   \n",
       "3                      False                      False   \n",
       "4                      False                      False   \n",
       "\n",
       "   NR(B0801)_AAKGRGAAL_NC_binder  \n",
       "0                          False  \n",
       "1                          False  \n",
       "2                          False  \n",
       "3                          False  \n",
       "4                          False  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellranger_out = pd.read_csv(fns[0])\n",
    "cellranger_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cellranger_out\n",
    "column_names = data.columns\n",
    "column_types = data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clonotype_id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>proportion</th>\n",
       "      <th>cdr3s_aa</th>\n",
       "      <th>cdr3s_nt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clonotype1</td>\n",
       "      <td>2407</td>\n",
       "      <td>0.050583</td>\n",
       "      <td>TRA:CAGHTGNQFYF;TRB:CASSWGGGSHYGYTF</td>\n",
       "      <td>TRA:TGTGCTGGTCACACCGGTAACCAGTTCTATTTT;TRB:TGTG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clonotype2</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.026143</td>\n",
       "      <td>TRA:CAARVRGFGNVLHC;TRA:CAVGDNFNKFYF;TRB:CASSLY...</td>\n",
       "      <td>TRA:TGTGCAGCAAGAGTGCGGGGCTTTGGGAATGTGCTGCATTGC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clonotype3</td>\n",
       "      <td>1167</td>\n",
       "      <td>0.024525</td>\n",
       "      <td>TRB:CASSWGGGSHYGYTF</td>\n",
       "      <td>TRB:TGTGCCAGCAGCTGGGGGGGCGGTAGCCACTATGGCTACACCTTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clonotype4</td>\n",
       "      <td>512</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>TRA:CAVSAASGGSYIPTF;TRB:CASSPRDRERGEQYF</td>\n",
       "      <td>TRA:TGTGCTGTGAGTGCAGCATCAGGAGGAAGCTACATACCTACA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>clonotype5</td>\n",
       "      <td>419</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>TRA:CAMNPAWGGATNKLIF;TRB:CSASPGDYEQYF</td>\n",
       "      <td>TRA:TGTGCAATGAACCCGGCGTGGGGTGGTGCTACAAACAAGCTC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clonotype_id  frequency  proportion   \n",
       "0   clonotype1       2407    0.050583  \\\n",
       "1   clonotype2       1244    0.026143   \n",
       "2   clonotype3       1167    0.024525   \n",
       "3   clonotype4        512    0.010760   \n",
       "4   clonotype5        419    0.008805   \n",
       "\n",
       "                                            cdr3s_aa   \n",
       "0                TRA:CAGHTGNQFYF;TRB:CASSWGGGSHYGYTF  \\\n",
       "1  TRA:CAARVRGFGNVLHC;TRA:CAVGDNFNKFYF;TRB:CASSLY...   \n",
       "2                                TRB:CASSWGGGSHYGYTF   \n",
       "3            TRA:CAVSAASGGSYIPTF;TRB:CASSPRDRERGEQYF   \n",
       "4              TRA:CAMNPAWGGATNKLIF;TRB:CSASPGDYEQYF   \n",
       "\n",
       "                                            cdr3s_nt  \n",
       "0  TRA:TGTGCTGGTCACACCGGTAACCAGTTCTATTTT;TRB:TGTG...  \n",
       "1  TRA:TGTGCAGCAAGAGTGCGGGGCTTTGGGAATGTGCTGCATTGC...  \n",
       "2  TRB:TGTGCCAGCAGCTGGGGGGGCGGTAGCCACTATGGCTACACCTTC  \n",
       "3  TRA:TGTGCTGTGAGTGCAGCATCAGGAGGAAGCTACATACCTACA...  \n",
       "4  TRA:TGTGCAATGAACCCGGCGTGGGGTGGTGCTACAAACAAGCTC...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cellranger_out = pd.read_csv(fns_clonotype[0])\n",
    "cellranger_out.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of column names of labels to predict in 10x raw files\n",
    "Here we take all antigens from 10x dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ids = [\n",
    "    'A0101_VTEHDTLLY_IE-1_CMV_binder',\n",
    "    'A0201_KTWGQYWQV_gp100_Cancer_binder',\n",
    "    'A0201_ELAGIGILTV_MART-1_Cancer_binder',\n",
    "    'A0201_CLLWSFQTSA_Tyrosinase_Cancer_binder',\n",
    "    'A0201_IMDQVPFSV_gp100_Cancer_binder',\n",
    "    'A0201_SLLMWITQV_NY-ESO-1_Cancer_binder',\n",
    "    'A0201_KVAELVHFL_MAGE-A3_Cancer_binder',\n",
    "    'A0201_KVLEYVIKV_MAGE-A1_Cancer_binder',\n",
    "    'A0201_CLLGTYTQDV_Kanamycin-B-dioxygenase_binder',\n",
    "    'A0201_LLDFVRFMGV_EBNA-3B_EBV_binder',\n",
    "    'A0201_LLMGTLGIVC_HPV-16E7_82-91_binder',\n",
    "    'A0201_CLGGLLTMV_LMP-2A_EBV_binder',\n",
    "    'A0201_YLLEMLWRL_LMP1_EBV_binder',\n",
    "    'A0201_FLYALALLL_LMP2A_EBV_binder',\n",
    "    'A0201_GILGFVFTL_Flu-MP_Influenza_binder',\n",
    "    'A0201_GLCTLVAML_BMLF1_EBV_binder',\n",
    "    'A0201_NLVPMVATV_pp65_CMV_binder',\n",
    "    'A0201_ILKEPVHGV_RT_HIV_binder',\n",
    "    'A0201_FLASKIGRLV_Ca2-indepen-Plip-A2_binder',\n",
    "    'A2402_CYTWNQMNL_WT1-(235-243)236M_Y_binder',\n",
    "    'A0201_RTLNAWVKV_Gag-protein_HIV_binder',\n",
    "    'A0201_KLQCVDLHV_PSA146-154_binder',\n",
    "    'A0201_LLFGYPVYV_HTLV-1_binder',\n",
    "    'A0201_SLFNTVATL_Gag-protein_HIV_binder',\n",
    "    'A0201_SLYNTVATLY_Gag-protein_HIV_binder',\n",
    "    'A0201_SLFNTVATLY_Gag-protein_HIV_binder',\n",
    "    'A0201_RMFPNAPYL_WT-1_binder',\n",
    "    'A0201_YLNDHLEPWI_BCL-X_Cancer_binder',\n",
    "    'A0201_MLDLQPETT_16E7_HPV_binder',\n",
    "    'A0301_KLGGALQAK_IE-1_CMV_binder',\n",
    "    'A0301_RLRAEAQVK_EMNA-3A_EBV_binder',\n",
    "    'A0301_RIAAWMATY_BCL-2L1_Cancer_binder',\n",
    "    'A1101_IVTDFSVIK_EBNA-3B_EBV_binder',\n",
    "    'A1101_AVFDRKSDAK_EBNA-3B_EBV_binder',\n",
    "    'B3501_IPSINVHHY_pp65_CMV_binder',\n",
    "    'A2402_AYAQKIFKI_IE-1_CMV_binder',\n",
    "    'A2402_QYDPVAALF_pp65_CMV_binder',\n",
    "    'B0702_QPRAPIRPI_EBNA-6_EBV_binder',\n",
    "    'B0702_TPRVTGGGAM_pp65_CMV_binder',\n",
    "    'B0702_RPPIFIRRL_EBNA-3A_EBV_binder',\n",
    "    'B0702_RPHERNGFTVL_pp65_CMV_binder',\n",
    "    'B0801_RAKFKQLL_BZLF1_EBV_binder',\n",
    "    'B0801_ELRRKMMYM_IE-1_CMV_binder',\n",
    "    'B0801_FLRGRAYGL_EBNA-3A_EBV_binder',\n",
    "    'A0101_SLEGGGLGY_NC_binder',\n",
    "    'A0101_STEGGGLAY_NC_binder',\n",
    "    'A0201_ALIAPVHAV_NC_binder',\n",
    "    'A2402_AYSSAGASI_NC_binder',\n",
    "    'B0702_GPAESAAGL_NC_binder',\n",
    "    'NR(B0801)_AAKGRGAAL_NC_binder'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of column names of negative controls in 10x raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_cols = [\n",
    "    'A0101_SLEGGGLGY_NC_binder',\n",
    "    'A0101_STEGGGLAY_NC_binder',\n",
    "    'A0201_ALIAPVHAV_NC_binder',\n",
    "    'A2402_AYSSAGASI_NC_binder',\n",
    "    'B0702_GPAESAAGL_NC_binder',\n",
    "    'NR(B0801)_AAKGRGAAL_NC_binder'\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Use these if you want binding counts instead of top binder categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BIND_COUNTS = True\n",
    "\n",
    "if USE_BIND_COUNTS:\n",
    "    target_ids = [\n",
    "        'A0101_VTEHDTLLY_IE-1_CMV',\n",
    "        'A0201_KTWGQYWQV_gp100_Cancer',\n",
    "        'A0201_ELAGIGILTV_MART-1_Cancer',\n",
    "        'A0201_CLLWSFQTSA_Tyrosinase_Cancer',\n",
    "        'A0201_IMDQVPFSV_gp100_Cancer',\n",
    "        'A0201_SLLMWITQV_NY-ESO-1_Cancer',\n",
    "        'A0201_KVAELVHFL_MAGE-A3_Cancer',\n",
    "        'A0201_KVLEYVIKV_MAGE-A1_Cancer',\n",
    "        'A0201_CLLGTYTQDV_Kanamycin-B-dioxygenase',\n",
    "        'A0201_LLDFVRFMGV_EBNA-3B_EBV',\n",
    "        'A0201_LLMGTLGIVC_HPV-16E7_82-91',\n",
    "        'A0201_CLGGLLTMV_LMP-2A_EBV',\n",
    "        'A0201_YLLEMLWRL_LMP1_EBV',\n",
    "        'A0201_FLYALALLL_LMP2A_EBV',\n",
    "        'A0201_GILGFVFTL_Flu-MP_Influenza',\n",
    "        'A0201_GLCTLVAML_BMLF1_EBV',\n",
    "        'A0201_NLVPMVATV_pp65_CMV',\n",
    "        'A0201_ILKEPVHGV_RT_HIV',\n",
    "        'A0201_FLASKIGRLV_Ca2-indepen-Plip-A2',\n",
    "        'A2402_CYTWNQMNL_WT1-(235-243)236M_Y',\n",
    "        'A0201_RTLNAWVKV_Gag-protein_HIV',\n",
    "        'A0201_KLQCVDLHV_PSA146-154',\n",
    "        'A0201_LLFGYPVYV_HTLV-1',\n",
    "        'A0201_SLFNTVATL_Gag-protein_HIV',\n",
    "        'A0201_SLYNTVATLY_Gag-protein_HIV',\n",
    "        'A0201_SLFNTVATLY_Gag-protein_HIV',\n",
    "        'A0201_RMFPNAPYL_WT-1',\n",
    "        'A0201_YLNDHLEPWI_BCL-X_Cancer',\n",
    "        'A0201_MLDLQPETT_16E7_HPV',\n",
    "        'A0301_KLGGALQAK_IE-1_CMV',\n",
    "        'A0301_RLRAEAQVK_EMNA-3A_EBV',\n",
    "        'A0301_RIAAWMATY_BCL-2L1_Cancer',\n",
    "        'A1101_IVTDFSVIK_EBNA-3B_EBV',\n",
    "        'A1101_AVFDRKSDAK_EBNA-3B_EBV',\n",
    "        'B3501_IPSINVHHY_pp65_CMV',\n",
    "        'A2402_AYAQKIFKI_IE-1_CMV',\n",
    "        'A2402_QYDPVAALF_pp65_CMV',\n",
    "        'B0702_QPRAPIRPI_EBNA-6_EBV',\n",
    "        'B0702_TPRVTGGGAM_pp65_CMV',\n",
    "        'B0702_RPPIFIRRL_EBNA-3A_EBV',\n",
    "        'B0702_RPHERNGFTVL_pp65_CMV',\n",
    "        'B0801_RAKFKQLL_BZLF1_EBV',\n",
    "        'B0801_ELRRKMMYM_IE-1_CMV',\n",
    "        'B0801_FLRGRAYGL_EBNA-3A_EBV',\n",
    "        'A0101_SLEGGGLGY_NC',\n",
    "        'A0101_STEGGGLAY_NC',\n",
    "        'A0201_ALIAPVHAV_NC',\n",
    "        'A2402_AYSSAGASI_NC',\n",
    "        'B0702_GPAESAAGL_NC',\n",
    "        'NR(B0801)_AAKGRGAAL_NC',\n",
    "    ]\n",
    "    nc_cols = [\n",
    "        'A0101_SLEGGGLGY_NC',\n",
    "        'A0101_STEGGGLAY_NC',\n",
    "        'A0201_ALIAPVHAV_NC',\n",
    "        'A2402_AYSSAGASI_NC',\n",
    "        'B0702_GPAESAAGL_NC',\n",
    "        'NR(B0801)_AAKGRGAAL_NC'\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model object\n",
    "EstimatorFfn() includes all of reading, training and testing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn = tm.models.EstimatorFfn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read 10x raw files, taking out TCR CDR3 and binarized binding matrix as training data\n",
    "We encode the TCR CDR3 amino acid sequences (include TRA and TRB) with one-hot encoding, the embedded sequences are of shape [num_samples, tra/trb, max_sequence_length, aa_onehot_dim]. For example if we take out 4000 TRB sequences seperately, the maximal length of sequences is 30 and we have 22 amino acids, the shape of output would be [4000, 1, 30, 26]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29618 clonotypes for 46526 observations in single file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1264: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  covariates_table[x] = cell_table[x].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19318 clonotypes for 77854 observations in single file.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n",
      "/Users/johnboesen/Documents/Code/#Work/tcellmatch/tcell-env/lib/python3.11/site-packages/tcellmatch/estimators/estimator_base.py:1364: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  table_temp[new_id] = table_temp[x].values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40500 clonotypes for 109637 observations and assigned to train data.\n"
     ]
    }
   ],
   "source": [
    "ffn.read_binarized_matrix(\n",
    "    fns=[indir + x for x in fns],\n",
    "    fns_clonotype=[indir + x for x in fns_clonotype],\n",
    "    fns_covar=[],\n",
    "    fn_blosum=f\"{indir}BLOSUM50.csv\",\n",
    "    blosum_encoding=False,\n",
    "    is_train=True,\n",
    "    # include categorical variable for which donor we get from\n",
    "    covariate_formula_categ=[\"donor\"],\n",
    "    covariate_formula_numeric=[],\n",
    "    # Whether to add an additional non-binder category for softmax activation function\n",
    "    add_non_binder_for_softmax=False,\n",
    "    # we are only keeping trb chain\n",
    "    chains=\"trb\",\n",
    "    label_cols=target_ids,\n",
    "    nc_cols=nc_cols\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input consists of TCR CDR3 sequences and covariates. Covariates act as a additional information which will be concatenated with TCR CDR3 sequences during training. The target set is a binarized matrix which shows the binding between TCR CDR3 and antigens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TCR sequences:  (109637, 1, 27, 26)\n",
      "Shape of covariates:  (109637, 2)\n",
      "Shape of target set:  (109637, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TCR sequences: \",ffn.x_train.shape)\n",
    "# print(\"The head of TCR sequences: \",ffn.x_train[0])\n",
    "print(\"Shape of covariates: \",ffn.covariates_train.shape)\n",
    "# print(\"The head of covariates: \",ffn.covariates_train[0:5])\n",
    "print(\"Shape of target set: \",ffn.y_train.shape)\n",
    "# print(\"The head of target set: \",ffn.y_train[0:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample clonotypes to data stored in x_train\n",
    "This avoids training, evaluation or test set being too biased toward a subset of TCRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled 40500 clonotypes from 109637 cells to 56887 cells.\n"
     ]
    }
   ],
   "source": [
    "# max_obs: Maximum number of observations per clonotype.\n",
    "ffn.downsample_clonotype(max_obs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TCR sequences:  (56887, 1, 27, 26)\n",
      "Shape of covariates:  (56887, 2)\n",
      "Shape of target set:  (56887, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TCR sequences: \",ffn.x_train.shape)\n",
    "print(\"Shape of covariates: \",ffn.covariates_train.shape)\n",
    "print(\"Shape of target set: \",ffn.y_train.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test dataset\n",
    "We can either split the training set or use a new database as the test set. Here, we split test set from training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in test data: 5828\n",
      "Number of observations in training+evaluation data: 51059\n"
     ]
    }
   ],
   "source": [
    "ffn.clear_test_data()\n",
    "ffn.sample_test_set(test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TCR CDR3 sequences for training:  (51059, 1, 27, 26)\n",
      "Shape of covariates for training:  (51059, 2)\n",
      "Shape of target set for training:  (51059, 50)\n",
      "Shape of TCR CDR3 sequences for test:  (5828, 1, 27, 26)\n",
      "Shape of covariates for test:  (5828, 2)\n",
      "Shape of target set for test:  (5828, 50)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TCR CDR3 sequences for training: \",ffn.x_train.shape)\n",
    "print(\"Shape of covariates for training: \",ffn.covariates_train.shape)\n",
    "print(\"Shape of target set for training: \",ffn.y_train.shape)\n",
    "print(\"Shape of TCR CDR3 sequences for test: \",ffn.x_test.shape)\n",
    "print(\"Shape of covariates for test: \",ffn.covariates_test.shape)\n",
    "print(\"Shape of target set for test: \",ffn.y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding TCR CDR3 sequences in both training and testing set\n",
    "Since we can use TCR CDR3 in another database as the test set, we should make sure they have same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.pad_sequence(target_len=40, sequence=\"tcr\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample data to given number of observations.\n",
    "In order to save time, we sample a small dataset for training. Never use this method in practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled train data from 51059 cells to 200 cells.\n",
      "Downsampled test data from 5828 cells to 200 cells.\n"
     ]
    }
   ],
   "source": [
    "# ffn.downsample_data(n=200, data=\"train\")\n",
    "# ffn.downsample_data(n=200, data=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TCR CDR3 sequences for training:  (200, 1, 40, 26)\n",
      "Shape of TCR CDR3 sequences for test:  (200, 1, 40, 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of TCR CDR3 sequences for training: \",ffn.x_train.shape)\n",
    "print(\"Shape of TCR CDR3 sequences for test: \",ffn.x_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save imported data as NumPy Arrays (optional)\n",
    "This can be useful if you want to avoid binarizing when debugging the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE_TO_NUMPY = True\n",
    "# if SAVE_TO_NUMPY:\n",
    "#     np.savez_compressed(\n",
    "#         f\"{indir}ffn_data_continuous.npz\",\n",
    "#         x_train=ffn.x_train,\n",
    "#         covariates_train=ffn.covariates_train,\n",
    "#         y_train=ffn.y_train,\n",
    "#         x_test=ffn.x_test,\n",
    "#         covariates_test=ffn.covariates_test,\n",
    "#         y_test=ffn.y_test,\n",
    "#         clone_train=ffn.clone_train\n",
    "#     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "Here, we can build two models: a BiLSTM-based or self-attention-based model, detailed above.\n",
    "\n",
    "Loss has the following possible parameters\n",
    "\n",
    "1. Discrete\n",
    "    1. Binary Crossentropy (param \"bce\")\n",
    "    2. Weighted Binary Crossentropy (param \"wbce\")\n",
    "    3. Categorical Crossentropy (param \"cce\")\n",
    "2. Continuous\n",
    "    1. MMD (param \"mmd\")\n",
    "    2. Mean Squared error (param \"mse\")\n",
    "    3. Poisson (param \"pois\")\n",
    "    \n",
    "Calling one of these creates the model and sets the ffn.model attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SELF_ATTENTION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SELF_ATTENTION:\n",
    "    ffn.build_self_attention(\n",
    "        residual_connection=True,\n",
    "        aa_embedding_dim=0,\n",
    "        # hidden size of each attention layer\n",
    "        attention_size=[5, 5],\n",
    "        # number of heads at each layer\n",
    "        attention_heads=[4, 4],\n",
    "        optimizer='adam',\n",
    "        lr=0.001,\n",
    "        loss='mmd' if USE_BIND_COUNTS else 'wbce',\n",
    "        label_smoothing=0\n",
    "    )\n",
    "else:\n",
    "    ffn.build_bilstm(\n",
    "        # The depth of each bilstm layer (length of feature vector)\n",
    "        topology = [10, 10],\n",
    "        residual_connection=True,\n",
    "        # Dimension of the linear amino acid embedding, ie number of 1x1 convolutional filters.\n",
    "        # set to input dimension if aa_embedding_dim==0.\n",
    "        aa_embedding_dim=0,\n",
    "        optimizer='adam',\n",
    "        lr=0.001,\n",
    "        loss='pois' if USE_BIND_COUNTS else 'wcbe',\n",
    "        label_smoothing=0,\n",
    "        # whether to assume covariates in model architecture\n",
    "        use_covariates=False,\n",
    "        # whether we are predicting max binding categorical\n",
    "        # or binding counts\n",
    "        one_hot_y=not USE_BIND_COUNTS\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model\n",
    "Train this model for 2 epochs     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in evaluation data: 19\n",
      "Number of observations in training data: 181\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 35\n",
    "train_curve, val_curve = ffn.train(\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=8,\n",
    "    # tensorboard logs to this directory\n",
    "    log_dir='training_runs',\n",
    "    # if true, saves epochs x n_classes as ffn.antigen_loss\n",
    "    # ijth element is loss of ith epoch on jth antigen\n",
    "    save_antigen_loss=False,\n",
    "    allow_early_stopping=True\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the curves\n",
    "plt.plot(train_curve, label='Train Curve')\n",
    "plt.plot(val_curve, label='Validation Curve')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Curves')\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this function to get the ouputs before our linear layer and store them for other use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.model.get_embeddings(torch.ones(1, 1, 40, 26)).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set\n",
    "This evaluates the data and returns binary and custom (i.e., based on how the model was built above) loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.evaluate(\n",
    "    # given k, returns loss only over the kth antigen in test\n",
    "    antigen_col=None\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{indir}saved_model', exist_ok=True)\n",
    "# save_yhat means save predictions\n",
    "ffn.save_model_full(f'{indir}saved_model', save_yhat=True, save_train_data=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate/Compare the Model\n",
    "We predict the labels on test data and store to `ffn.predictions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.predict()\n",
    "ffn.predictions.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Confusion Matrix\n",
    "This is only applicable, of course, if you've used the one-hot encoded maximum binding y-data. If it is, you can use this to also compare with the original tcellmatch in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_BIND_COUNTS:\n",
    "    true_labels = np.argmax(ffn.y_test, axis=1)\n",
    "    predicted_labels = np.argmax(ffn.predictions, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce evaluation in a new instance of model w/ same weights\n",
    "\n",
    "We load the model, with weights and data included, and evaluate and predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn2 = tm.models.EstimatorFfn()\n",
    "ffn2.load_model(fn=f'{indir}saved_model')\n",
    "print(ffn2.evaluate(test_only=True))\n",
    "# saves to ffn2.predictions\n",
    "ffn2.predict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Residuals\n",
    "This function outputs a MatPlotLib histogram of the residuals of the given antigen index (here `0`) over the test data. `predict()` must be called first to generate our test predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffn.plot_residuals(antigen_idx=0, target_ids=target_ids)\n",
    "ffn.compare_preds(antigen_idx=0, target_ids=target_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcell-env",
   "language": "python",
   "name": "tcell-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
